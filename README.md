----

### Machine Learning

This course provides an introduction to machine learning. Machine learning explores the study and construction of algorithms that can learn from and make predictions on data. Such algorithms operate by building a model from example inputs in order to make data-driven predictions or decisions, rather than following strictly static program instructions.

Topic categories include supervised, unsupervised, and reinforcement learning. Students will learn how to apply machine learning methods to solve problems in computer vision, natural language processing, classification, and prediction. Fundamental and current state-of-the-art methods including boosting and deep learning will be covered. Students will reinforce their learning of machine learning algorithms with hands-on tutorial oriented laboratory exercises for development of representative applications. Lectures are augmented with hands-on tutorials using Jupyter Notebooks. Laboratory assignments will be completed using Python and related data science packages: NumPy, Pandas, ScipPy, StatsModels, Scikit-learn, Matplotlib, TensorFlow, Keras, PyTorch.

Prerequisites: MA-262 Probability and Statistics; programming maturity, and the ability to program in Python.  

Helpful: CS3851 Algorithms, MA-383 Linear Algebra, Data Science.  

ABET: Math/Science, Engineering Topics.

2-2-3 (class hours/week, laboratory hours/week, credits)


2 hours of weekly lectures and 2-hour labs are provided each week. Lectures are augmented with hands-on tutorials using Jupyter Notebooks. Laboratory assignments will be completed using Python and related data science packages: NumPy, Pandas, ScipPy, StatsModels, Scikit-learn, Matplotlib, TensorFlow, Keras, PyTorch.

Prerequisites: MA-262 Probability and Statistics; programming maturity, and the ability to program in Python.  

Helpful: CS3851 Algorithms, MA-383 Linear Algebra, Data Science.  

ABET: Math/Science, Engineering Topics.

Outcomes:   
- Understand the basic types of of machine learning:    
- Understand the concepts of learning theory, i.e., what is learnable, bias, variance, overfitting.
- Understand the concepts and application of supervised, unsupervised, semi-supervised, and reinforcement learning.
- Understand the application of learned models to problems in classification, prediction, clustering, time-series, computer vision, and NLP.
- The ability to identify, load, and prepare a data set for a given problem.  
- The ability to analyze a data set including the ability to understand which data attributes (dimensions) affect the outcome.  
- The ability to assess the quality of predictions and inferences.  
- The ability to apply methods to real world data sets.  

Tools: Python and related packages for data analysis, machine learning, and visualization. Jupyter Notebooks.  

References:  

[Hands-On Machine Learning with Scikit-Learn and TensorFlow
Concepts, Tools, and Techniques to Build Intelligent Systems, Aurélien Géron. O'Reilly Media, 2017](http://shop.oreilly.com/product/0636920052289.do)

[Deep Learning with Python, François Chollet. Manning, 2017.](https://www.manning.com/books/deep-learning-with-python)

[Deep Learning, Ian Goodfellow, Yoshua Bengio, and Aaron Courville. MIT Press, 2016.](https://www.deeplearningbook.org/)

[An Introduction to Statistical Learning: with Applications in R]. Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. 2015 Edition, Springer.](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf)

[Python Data Science Handbook, Jake VanderPlas, O'Reilly.](https://jakevdp.github.io/PythonDataScienceHandbook/)

Mining of Massive Datasets. Anand Rajaraman and Jeffrey David Ullman. http://infolab.stanford.edu/~ullman/mmds.html

---

### Week 1: Intro to Machine Learning, Linear Regression

#### Lecture:    
1. [Introduction to Machine Learning](slides/IntroMachineLearning.pdf)   
- Demonstrations   

2. [Linear Regression](slides/LinearRegressionML_Jay.pdf)  

#### Lab Notebooks:
- [Jupyter Notebooks](labs/lab_0_python/lab_0_jupyter.ipynb)
- [Python Machine Learning Environment](labs/lab_0_python/python_programming_style.ipynb)
- [Python Programming](labs/lab_0_python/lab_0_python.ipynb)  *Submission required*

#### Optional tutorial notebooks:   
- [Dates and Time](https://github.com/jayurbain/DataScienceIntro/blob/master/notebooks/2&#32;-&#32;Dates&#32;and&#32;Time.ipynb>)  
- [Python Objects, Map, Lambda, and List Comprehensions](<notebooks/3&#32;-&#32;Python&#32;Objects&#32;Map&#32;Lambda&#32;List&#32;Comprehensions.ipynb>)
- [Python Numpy](https://github.com/jayurbain/DataScienceIntro/blob/master/notebooks/4&#32;-&#32;Python&#32;Numpy.ipynb) *Submission required*   
- [Python Numpy Aggregates](https://github.com/jayurbain/DataScienceIntro/blob/master/notebooks/5&#32;-&#32;Python&#32;Numpy&#32;Aggregates.ipynb)
- [Pandas Data Manipulation](https://github.com/jayurbain/DataScienceIntro/blob/master/notebooks/6&#32;-&#32;Pandas&#32;Data&#32;Manipulation.ipynb)   
- [Python Reading and Writing CSV files](https://github.com/jayurbain/DataScienceIntro/blob/master/notebooks/7&#32;-&#32;Python&#32;Reading&#32;and&#32;Writing&#32;CSV&#32;files.ipynb)  
- [Data Visualization](https://github.com/jayurbain/DataScienceIntro/blob/master/notebooks/8&#32;-&#32;Data&#32;Visualization.ipynb)  

Outcomes addressed in week 1:   
- Understand the process of machine learning
- Understand the concepts and application of supervised, unsupervised, semi-supervised, and reinforcement learning.

---

### Week 2: Gradient Descent Learning, Logistic Regression

#### Lecture:   

1. [Gradient Descent](slides/LogisticRegressionML_Jay.pdf)   
- [http://jayurbain.com/msoe/cs498-machinelearning/Normal%20Equation%20derivation%20for%20linear%20regression.pdf](http://jayurbain.com/msoe/cs498-machinelearning/Normal%20Equation%20derivation%20for%20linear%20regression.pdf)   

2. [Logistic Regression](notebooks/5&#32;-&#32;Python&#32;Numpy&#32;Aggregates.ipynb)    

#### Lab Notebooks:
- [Gradient Descent Learning](notebooks/gradient_descent_assignment.ipynb) *Submission required*

#### Optional exercise:   
[Online Machine Learning with Stochastic Gradient Descent](notebooks/Online%20Machine%20Learning.ipynb)

Outcomes addressed in week 2:   
- Understand the concepts of learning theory, i.e., what is learnable, bias, variance, overfitting.
- Understand the concepts and application of supervised, unsupervised, semi-supervised, and reinforcement learning.  

---

### Week 3: Model Selection and Regularization, Decision Trees  

#### Lecture:   

1. [Model selection and regularization](slides/Regularization_and_overfittingML.pdf)  

2. [Decision Trees, Overfitting, Model Selection, Techniques to Improve Classifier Accuracy Slides](slides/dm08ClassBasic.pdf)  
- [Information Gain Calculation Spreadsheet](http://jayurbain.com/msoe/cs4881/infogain.xls)

#### Lab Notebooks:
[Introduction to Machine Learning with SciKit Learn.ipynb](notebooks/Introduction%20to%20Machine%20Learning%20with%20SciKit%20Learn.ipynb)
[Supervised Learning - Linear Regression](notebooks/Supervised%20Learning%20-%20%20Linear%20Regression.ipynb)   *Submission required*
[Supervised Learning - Logistic Regression](notebooks/Supervised%20Learning%20-%20Logistic%20Regression.ipynb)  *Submission required*
[Generalized Linear Models](notebooks/Generalized%20Linear%20Models%20and%20Regularization.ipynb)

Outcomes addressed in week 3:   
- Understand the concepts and application of supervised, unsupervised, semi-supervised, and reinforcement learning.  
- Understand the application of learned models to problems in classification, prediction, clustering, time-series, computer vision, and NLP.

---

#### Week 10:  Deep Learning for NLP


#### Lab Notebooks:  


#### Week 4: Probabilistic Models

#### Lecture:

1. [Validation, Bagging, Boosting, Random Forests](slides/09_validation_boostrap_boosting.pdf)

2. [Naive Bayes Slides 87-102](slides/dm08ClassBasic.pdf)

3. [Bayesian Networks](slides/m14-bayesian.pdf)  *optional*   
- [BayesianNetworkSprinklerExample.xls](slides/BayesianNetworkSprinklerExample.xls)

#### Lab Notebooks:  

- [Decision Trees with Scikit Learn](notebooks/Decision%20Trees.ipynb) *Submission required*   
- [Random Forests and Boosting](labs/Lab9_DT_RF_Boosting/RF_and_Boosting.ipynb)  
- XGBoost?  

Outcomes addressed in week 4:   
- The ability to analyze a data set including the ability to understand which data attributes (dimensions) affect the outcome.  
- The ability to perform basic data analysis and statistical inference.  
- The ability to perform supervised learning of prediction models.
- The ability to perform data visualization and report generation.   
- The ability to apply methods to real world data sets.

---

### Week 5: Unsupervised Learning

#### Lecture:

1. [K-Means Clustering](slides/dm10ClusBasic.pdf)  
2. [Hierarchical Agglomerative and Probabilistic Clustering](slides/dm10ClusBasic.pdf)  

#### Lab Notebooks:   
- [Supervised Learning - Logistic Regression](notebooks/Clustering.ipynb)  *Submission required*      

Outcomes addressed in week 5:   
- Understand the concepts and application of supervised, unsupervised, semi-supervised, and reinforcement learning.
- Understand the application of learned models to problems in classification, prediction, clustering, time-series, computer vision, and NLP.

---

#### Week 6: Midterm, Dimensionality Reduction

#### Lecture:
1. [Dimensionality Reduction](slides/09_imensionality_reduction.pdf)  

2. [Midterm exam](http://jayurbain.com/msoe/cs498-machinelearning/Machine%20Learning%20Midterm%20Exam%20Review.pdf)  

#### Lab Notebooks:     

#### Lab Notebooks:   
- [SVD](notebooks/Lab6_Classification_PCA/Singular&#32;Value&#32;Decomposition.ipynb)  *Submission required*   
- [PCA](notebooks/Lab6_Classification_PCA/classification-and-pca-lab.ipynb)   *Submission required*  

Outcomes addressed in week 6:

---

#### Week 7: Introduction to Neural Networks and Deep Learning  

#### Lecture:
1. [Introduction to Deep Learning](https://github.com/jayurbain/DeepNLPIntro/blob/master/slides/1%20Deep%20Learning%20Introduction.pdf)

2. Hands-on: [Introduction to TensorFlow](https://github.com/jayurbain/TensorFlowIntro) *Submission required*    

3. [Neural Networks - Representation and Learning](slides/neuralnetwork.pdf)  

#### Lab Notebooks:   
- [Neural Network Principles](notebooks/NeuralNetworkIntro-Student.ipynb) *Submission required*   

Outcomes addressed in week 8:

#### Week 8: Deep Learning for Computer Vision

#### Lecture:

1. [Clustering - K-Means](slides/12_clustering.pdf)  

2. [Clustering - Hierarchical, Probabilistic](slides/12_clustering.pdf)  

#### Lab Notebooks:   
[K-Means Clustering](labs/Lab8_Clustering/K-Means.ipynb) *Submission required*   

[Introduce Data Science Project]()  

Outcomes addressed in week 9:

---

#### Week 9: Deep Learning for NLP

#### Lecture:

2. [NLP Classification](https://github.com/jayurbain/DeepNLPIntro/blob/master/slides/2%20NLP%20Text%20Classification.pdf)

2. [NLP Translation](https://github.com/jayurbain/DeepNLPIntro/blob/master/slides/3%20NLP%20Text%20Translations.pdf)

#### Lab Notebooks:     
- [NLP Classification](https://github.com/jayurbain/DeepNLPIntro)   
- [NLP Translation ](labs/Lab6_Classification_PCA/classification-and-pca-lab.ipynb)   

Outcomes addressed in week 9:   
- The ability to perform unsupervised learning.  
- The ability to perform data visualization and report generation.   

---

#### Week 10:  Generative Deep Learning

#### Lecture:
1. [Validation, Bagging, Boosting, Random Forests](slides/09_validation_boostrap_boosting.pdf)  

2. Review   

#### Lab Notebooks:  
Complete assignments   

Outcomes addressed in week 10:

---
