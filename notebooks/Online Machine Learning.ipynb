{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online Machine Learning with Stochastic Gradient Descent\n",
    "\n",
    "Jay Urbain, PhD\n",
    "\n",
    "3/24-30/2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Machine Learning\n",
    "\n",
    "The goal of online learning is to make a sequence of accurate predictions given knowledge of the correct answer to previous prediction tasks and possibly additional available information.\n",
    "\n",
    "Weather forecasting, predicting stock market trends, and deciding which ads to present on a web page are examples of sequential prediction problems. An online learning algorithm observes a stream of examples and makes a prediction for each element in the stream. The algorithm receives immediate feedback about each prediction and uses this feedback to improve its accuracy on subsequent predictions. \n",
    "\n",
    "More generally, as data becomes available in a sequential order, it is used to update our best *prediction model* for future data at each step. This is in contrast to **batch learning** techniques which generate the best predictor by learning on an entire training data set at once. \n",
    "\n",
    "*Online learning* is commonly used where it is computationally infeasible to train over the entire dataset, requiring the need of *out-of-core* algorithms, i.e., algorithms that do not require the entire training set to fit within memory.  It is also used in situations where it is necessary for the algorithm to dynamically adapt to new patterns in the data, or when the data itself is generated as a function of time, e.g. stock price prediction, click through rates, or changing sensor data.\n",
    "\n",
    "There has been a recent surge of scientific research in online learning algorithms, largely due to their broad applicability to web-scale prediction problems. Online learning is also used as a fundamental model of how humans learn.\n",
    "\n",
    "Two general modeling strategies exist for online learning models: \n",
    "\n",
    "- statistical learning models. \n",
    "\n",
    "- adversarial models. \n",
    "\n",
    "In **statistical learning models** (e.g. stochastic gradient descent, perceptrons), the data samples are assumed to be independent and identically distributed (**IID**) random variables, and our algorithm has limited access to the data. In prediction, the sequence of elements (outcomes) are generated by a stochastic process. The statistical properties of the process may be estimated on the basis of the sequence of past observations, and effective prediction rules can be derived from these estimates. In this setup, the *risk* of a prediction rule may be defined as the expected value of some loss (cost) function measuring the discrepancy between the predicted value and the true outcome. Different rules are compared based on the behavior of their risk.\n",
    "\n",
    "In **adversarial models**, online learning algorithms do not make stochastic assumptions about the data they observe, and even handle situations where the data is generated by a malicious adversary. The learning problem is modeled as a game between two players (the learner vs. the data generator), and we are trying to minimize our losses regardless of the move played by the other player. In this model, the opponent is allowed to dynamically adapt the data generated based on the output of the learning algorithm. Spam filtering falls in this category, as the adversary will dynamically generate new spam based on the current behavior of the spam detector. Examples of algorithms in this model include follow the leader, follow the regularized leader, etc. *Note: The adversary is not necessarily a true adversary, but a natural proces we are trying to predict, e.g., the weather, stocks, etc.\n",
    "\n",
    "Without a probabilistic model, the notion of risk cannot be defined since it is not clear how the goals of prediction should be set up. In a basic model, the performance of the forecaster is measured by the loss accumulated during many rounds of prediction, where loss is scored by some fixed loss function. To avoid any assumption on the way the sequence is generated, a class of reference *forecasters* (*experts*, or *leaders*) is introduced. These *experts* make their prediction available to the *forecaster* before the next outcome is revealed. The *forecaster* can then make their own prediction depend om the *expert's* advice in order to keep their cummulative loss close to that of the best reference forecaster in the class.\n",
    "\n",
    "The difference between the forecaster's accumulated loss and that of an expert is called *regret*, since it measures how much the forecaster regrets, in hindsight, not following the *expert's* advice. Keeping *regrets* small depends on the data, the size and structure of the experts, and on the loss function.\n",
    "\n",
    "**Online learning algorithm**\n",
    "\n",
    "for $t=1, 2, ...$\n",
    "\n",
    "$\\ \\ \\ \\ $The learner is presented with a new example $x_t \\in X$\n",
    "    \n",
    "$\\ \\ \\ \\ $The learner predicts a label $\\hat{y_t} \\in Y$\n",
    "    \n",
    "$\\ \\ \\ \\ $After the prediction is made, the true label $y_t$ of the example is revealed\n",
    "    \n",
    "$\\ \\ \\ \\ $The learner suffers $loss(\\hat{y_t},y_t)$, updates prediction rule based on $x_t, \\hat{y_t}$, and $y_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "**Gradient descent** is a first-order optimization algorithm for **batch learning**. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient of the function at the current point. If instead one takes steps proportional to the positive of the gradient, one approaches a local maximum of that function. The procedure is then known as gradient ascent.\n",
    "\n",
    "The advantages of Gradient Descent (GD) are:\n",
    "\n",
    "- Efficiency.\n",
    "\n",
    "- Ease of implementation.\n",
    "\n",
    "The disadvantages of Gradient Descent include:\n",
    "\n",
    "- Iterates over the entire training data set multiple times, i.e., it is an in-memory algorithm.\n",
    "\n",
    "- Requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
    "\n",
    "- Sensitive to feature scaling.\n",
    "\n",
    "- **Not suitable for online-learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression with gradient descent**\n",
    "\n",
    "Hypothesis function, $h_{\\theta}$ = linear model\n",
    "\n",
    "$h_{\\theta} = \\sum_{j=0}^{n}\\theta_jx_j = \\theta_0x_0 + + \\theta_0x_0 + ... + \\theta_nx_n$\n",
    "\n",
    "Fit linear model by minimizing a cost fuction $J_{train}(\\theta)$, which minimizes the residual sum of squares between the fitted model and the actual training data.\n",
    "\n",
    "$J_{train}(\\theta) = \\dfrac{1}{2m}\\sum_{j=0}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "Algorithm: \n",
    "\n",
    "- Iterate multiple times (epochs) over the entire training set.\n",
    "\n",
    "- For each *iteration*, update coefficients: $\\theta_j, j=1, 2, ..., n$ based on taking the derivative of the cost function, $J_{train}(\\theta)$\n",
    "\n",
    "$\\ \\ $**Repeat** { \n",
    "\n",
    "$\\ \\ \\ \\ \\ \\theta_j = \\theta_j - \\alpha\\dfrac{1}{m}\\sum_{j=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}$\n",
    "\n",
    "$\\ \\ \\ \\ $ // Update $\\theta_j$ for $j=0, 1, 2, ..., n)$\n",
    "\n",
    "$\\ \\ $}\n",
    "\n",
    "Where:\n",
    "\n",
    "$\\alpha$ - learning rate\n",
    "\n",
    "$\\theta$ - coefficients to be learned\n",
    "\n",
    "$x^{(i)}$ - input sample, with variables $x_j$\n",
    "\n",
    "$y^{(i)}$ - target variable\n",
    "\n",
    "\\* can be adapted for discriminative learning/classification, e.g., logistic regression, support vector machines, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Logistic Function**\n",
    "\n",
    "The [Logistic Function](http://en.wikipedia.org/wiki/Logistic_function) takes an input $(-\\infty , +\\infty)$, and outputs a value between 0 and 1. \n",
    "\n",
    "The logistic function is defined as:\n",
    "\n",
    "$g(z)= \\dfrac{1}{1+e^{-z}}$\n",
    "\n",
    "Where $z=\\beta^TX = \\beta _0 x_{i_0} + ... + \\beta_p x_{ip}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the [Logisitc Function](http://matplotlib.org/users/mathtext.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 1. Logistic Function\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEXCAYAAABoPamvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\na6L7NjMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a7d0fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# plots within notebook versus launching a separate window\n",
    "%matplotlib inline \n",
    "\n",
    "x = np.linspace(-20, 20, 1000)\n",
    "beta = [0, 0.5]\n",
    "y = np.exp(beta[0] + beta[1]*x) / (1 + np.exp(beta[0] + beta[1]*x))\n",
    "\n",
    "# Plotting\n",
    "plt.plot(x, y, 'r', alpha=0.75, linewidth=2.5)\n",
    "plt.plot([0,0], [0, 1], 'k')\n",
    "plt.plot([-20,20], [0.5, 0.5], 'k')\n",
    "plt.xlabel(r'$z$', fontsize='xx-large')\n",
    "plt.ylabel(r'$g(z)$', fontsize='xx-large')\n",
    "\n",
    "print (\"Figure 1. Logistic Function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification: Logistic Regression**\n",
    "\n",
    "Basically apply logistic function to linear regression model to force values to 1 or 0.\n",
    "\n",
    "The logistic function is defined as:\n",
    "\n",
    "$g(z)= \\dfrac{1}{1+e^{-z}}$\n",
    "\n",
    "Where $z= \\theta_0x_0 + + \\theta_0x_0 + ... + \\theta_nx_n$\n",
    "\n",
    "New hypothesis function becomes:\n",
    "\n",
    "$h_{\\theta} = g( \\theta_jx_j = \\theta_0x_0 + + \\theta_0x_0 + ... + \\theta_nx_n )$\n",
    "\n",
    "\n",
    "Fit linear model by minimizing a cost fuction $J_{train}(\\theta)$, which minimizes the residual sum of squares between the fitted model and the actual training data.\n",
    "\n",
    "$cost(\\theta, (x^{(i)}, y^{(i)})) =$\n",
    "- $-log(h_{\\theta}(x))$, if $y=1$\n",
    "- $-log(1-h_{\\theta}x))$,  if $y=1$\n",
    "       \n",
    "$J_{train}(\\theta) = \\dfrac{1}{m}\\sum_{j=0}^{m} cost(\\theta, (x^{(i)}, y^{(i)}))\n",
    "= \\dfrac{1}{m}\\sum_{j=0}^{m} y^{(i)}log(h_{\\theta}(x^{(i)})) + (1-y^{(i)}) log(1 - h_{\\theta}(x^{(i)}))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting logistic regression\n",
    "\n",
    "log odds = $log\\big(\\dfrac{e^{\\beta_0+\\beta_1x}}{1-e^{\\beta_0+\\beta_1x}}\\big) = \\beta_0+\\beta_1x$\n",
    "\n",
    "Increasing $x_1$ by one unit changes the log odds by $\\beta_1$, or equivalently \n",
    "it multiplies the odds by $e^{\\beta_1}$. \n",
    "\n",
    "Because the relationship between $f(X)$ and $X$ is not a straight line, $\\beta_1$ does not correspond to the change \n",
    "in $f(X)$ associated with a one-unit increase in $X$. The amount that \n",
    "$f(X)$ changes due to a one-unit change in $X$ will depend on the current \n",
    "value of $X$.\n",
    "\n",
    "In our example, β1 = ~= 0.0043\n",
    "\n",
    "Log-odds: \n",
    "If you increase x by 1, you increase the log-odds by 0.0043. \n",
    "If you increase x by 800, you increase the log-odds by 0.0043*800 = 3.44\n",
    "\n",
    "If you increase x by 1, you multiply the odds by e^0.0043. \n",
    "If you increase x by 800, you mutliply the odds by e^(0.0043*800) = 31.187, not 800 * e^(0.0043)\n",
    "\n",
    "[Log-odds](https://en.wikipedia.org/wiki/Logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "**Stochastic Gradient Descent** (SGD) is a relatively simple and very efficient approach to linear regression, and learning of linear classifiers under convex loss functions such as Logistic Regression and (linear) Support Vector Machines. \n",
    "\n",
    "Even though **SGD** has been around in the machine learning community for a long time, it has received a considerable amount of attention recently in the context of large-scale learning, and continuous online learning.\n",
    "\n",
    "**SGD** has been applied to large-scale and sparse machine learning problems often encountered in text classification and natural language processing. Given that the data is sparse, the classifiers in this module can easily scale to problems with more than $10^5$ training examples and more than $10^5$ features.\n",
    "\n",
    "The advantages of Stochastic Gradient Descent are:\n",
    "\n",
    "- Efficiency.\n",
    "\n",
    "- Ease of implementation (lots of opportunities for code tuning).\n",
    "\n",
    "- **Suitable for online learning**.\n",
    "\n",
    "The disadvantages of Stochastic Gradient Descent include:\n",
    "\n",
    "- SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
    "\n",
    "- SGD is sensitive to feature scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression with *stochastic* gradient descent\n",
    "\n",
    "Hypothesis function = linear model\n",
    "\n",
    "$h_{\\theta} = \\sum_{j=0}^{n}\\theta_jx_j = \\theta_0x_0 + + \\theta_0x_0 + ... + \\theta_nx_n$, where $x_0=1$\n",
    "\n",
    "Fit linear model by minimizing a cost fuction $J_{train}(\\theta)$, which minimizes the residual sum of squares between the fitted model and the actual training data.\n",
    "\n",
    "$cost(\\theta, (x^{(i)}, y^{(i)})) = \\dfrac{1}{2}(h_{\\theta}(x^{(i)}) - y^{(i)})^2$\n",
    "       \n",
    "$J_{train}(\\theta) = \\dfrac{1}{2m}\\sum_{j=0}^{m} cost(\\theta, (x^{(i)}, y^{(i)}))$\n",
    "\n",
    "Algorithm: \n",
    "\n",
    "- Randomly shuffle data set for non-deterministic data  (**batch learning**) \n",
    "\n",
    "- Iterate over each *sample*, $x^{(i)}$ in the training set. For each *sample*, update coefficients: $\\theta_j, j=1, 2, ..., n$\n",
    "\n",
    "- The update to $\\theta_j$ is based on taking the derivative of the cost function, $(x^{(i)}) - y^{(i)})x_j^{(i)}$.\n",
    "\n",
    "**Repeat** {  \n",
    "\n",
    "$\\ \\ $for $i=1,...,m$ {\n",
    "\n",
    "$\\ \\ \\ \\ \\ \\theta_j = \\theta_j - \\alpha(h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}$\n",
    "\n",
    "$\\ \\ \\ \\ $ // Update $\\theta_j$ for $j=0, 1, 2, ..., n)$\n",
    "\n",
    "$\\ \\ $}\n",
    "\n",
    "}\n",
    "\n",
    "Where:\n",
    "\n",
    "$\\alpha$ - learning rate\n",
    "\n",
    "$\\theta$ - coefficients to be learned\n",
    "\n",
    "$x^{(i)}$ - input sample, with variables $x_j$\n",
    "\n",
    "$y^{(i)}$ - target variable\n",
    "\n",
    "\\* can be adapted for discriminatie learning/classification, e.g., logistic regression, support vector machines, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron with gradient descent\n",
    "\n",
    "A perceptron takes a vector of real-valued inputs, calculates a linear combination of these inputs, then outputs a 1 if the result is greater than some threshold and -1 otherwise.\n",
    "\n",
    "More precisely, given inputs $x_1$ through $x_n$, the output $o(x_1,...,x_n$ computed by the perceptron is:\n",
    "                                                               \n",
    "$o(x_1,...,x_n= 1$ if $w_0+w_1x_1 + w_2x_2 + ... + w_nx_n >0$\n",
    "\n",
    "$0$ otherwise.\n",
    "\n",
    "Notation is simplified by setting $x_0=$, allowing is to write the inequality for classification as:\n",
    "\n",
    "$\\sum^{n}_{i=0}w_ix_i > 0$\n",
    "\n",
    "**Perceptron learning algorithm**: use SGD\n",
    "\n",
    "- Initialize weight vector to random weights, then iteratively apply the perceptron to each training example, modifying the perceptron weights whenever it misclassifies an example.\n",
    "\n",
    "- This process is repeated, iterating through the training examples as many times as needed until the perceptron classifies all training examples *correctly*.\n",
    "\n",
    "- Weights are modified at each step acording to the *perceptron* (delta) training rule.\n",
    "\n",
    "**Perceptron training rule**\n",
    "\n",
    "$w_i <- w_i + \\delta{w_i}$\n",
    "\n",
    "where $\\delta{w_i}=\\eta(t - o)x_i$\n",
    "\n",
    "- $t$ is the target output\n",
    "\n",
    "- $\\eta$ is a positive contstant representing the learing rate.\n",
    "\n",
    "- $o$ is the output generated by the perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batch gradient descent\n",
    "\n",
    "A hybrid learning approach where a dataset is learned in successive batches, and the results are averaged.\n",
    "\n",
    "Useful for paralleization, and when examples arrive in batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative (recursive) least squares online learning\n",
    "\n",
    "The method of iteratively reweighted least squares (IRLS) can be used to continually relearn all previous samples.\n",
    "\n",
    "\n",
    "$\\ \\ $for  $m=1,2,3,...$ { \n",
    "\n",
    "$\\ \\ \\ \\ \\ \\theta_j = \\theta_j - \\alpha\\dfrac{1}{m}\\sum_{j=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}$\n",
    "\n",
    "$\\ \\ \\ \\ $ // Update $\\theta_j$ for $j=0, 1, 2, ..., n)$\n",
    "\n",
    "$\\ \\ $}\n",
    "\n",
    "Where:\n",
    "\n",
    "$\\alpha$ - learning rate\n",
    "\n",
    "$\\theta$ - coefficients to be learned\n",
    "\n",
    "$x^{(i)}$ - input sample, with variables $x_j$\n",
    "\n",
    "$y^{(i)}$ - target variable\n",
    "\n",
    "The advantages of recursive learning are:\n",
    "\n",
    "- Fast convergence.\n",
    "\n",
    "- Ease of implementation.\n",
    "\n",
    "- **Suitable for online learning**.\n",
    "\n",
    "The disadvantages of recursive learning include:\n",
    "\n",
    "- Requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
    "\n",
    "- Sensitive to feature scaling.\n",
    "\n",
    "- Requires all examples to be held in memory.\n",
    "\n",
    "- Update of model parameters slower.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing different classification loss functions\n",
    "\n",
    "Given a set of training examples $(x_1, y_1), \\ldots, (x_n, y_n)$ where $x_i \\in \\mathbf{R}^n$ and $y_i \\in \\{-1,1\\}$, our goal is to learn a linear scoring function $f(x) = w^T x + b$ with model parameters $w \\in \\mathbf{R}^m$ and intercept $b \\in \\mathbf{R}$. \n",
    "\n",
    "In order to make predictions, we simply look at the sign of $f(x)$. A common choice to find the model parameters is by minimizing the regularized training error given by:\n",
    "\n",
    "$E(w,b) = \\frac{1}{n}\\sum_{i=1}^{n} L(y_i, f(x_i)) + \\alpha R(w)$\n",
    "\n",
    "where $L$ is a loss function that measures model (mis)fit and R is a regularization term (aka penalty) that penalizes model complexity; $\\alpha > 0$ is a non-negative hyperparameter.\n",
    "\n",
    "Different choices for L entail different classifiers such as:\n",
    "\n",
    "- Hinge: (soft-margin) Support Vector Machines.\n",
    "\n",
    "- Log: Logistic Regression.\n",
    "\n",
    "- Least-Squares: Ridge Regression.\n",
    "\n",
    "- Epsilon-Insensitive: (soft-margin) Support Vector Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEUCAYAAADDdzb+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHvm+RIcSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a96d7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def modified_huber_loss(y_true, y_pred):\n",
    "    z = y_pred * y_true\n",
    "    loss = -4 * z\n",
    "    loss[z >= -1] = (1 - z[z >= -1]) ** 2\n",
    "    loss[z >= 1.] = 0\n",
    "    return loss\n",
    "\n",
    "\n",
    "xmin, xmax = -4, 4\n",
    "xx = np.linspace(xmin, xmax, 100)\n",
    "plt.plot([xmin, 0, 0, xmax], [1, 1, 0, 0], 'k-',\n",
    "         label=\"Zero-one loss\")\n",
    "plt.plot(xx, np.where(xx < 1, 1 - xx, 0), 'g-',\n",
    "         label=\"Hinge loss\")\n",
    "plt.plot(xx, -np.minimum(xx, 0), 'm-',\n",
    "         label=\"Perceptron loss\")\n",
    "plt.plot(xx, np.log2(1 + np.exp(-xx)), 'r-',\n",
    "         label=\"Log loss\")\n",
    "plt.plot(xx, np.where(xx < 1, 1 - xx, 0) ** 2, 'b-',\n",
    "         label=\"Squared hinge loss\")\n",
    "plt.plot(xx, modified_huber_loss(xx, 1), 'y--',\n",
    "         label=\"Modified Huber loss\")\n",
    "plt.ylim((0, 8))\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(r\"Decision function $f(x)$\")\n",
    "plt.ylabel(\"$L(y, f(x))$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SGD in scikit-learn\n",
    "\n",
    "SGD has to be fitted with two arrays: an array X of size [n_samples, n_features] holding the training samples, and an array Y of size [n_samples] holding the target values (class labels) for the training samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After being fitted, the model can then be used to predict new values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2., 2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SGD\n",
      "training ASGD\n",
      "training Perceptron\n",
      "training Passive-Aggressive I\n",
      "training Passive-Aggressive II\n",
      "training SAG\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier, Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "heldout = [0.95, 0.90, 0.75, 0.50, 0.01]\n",
    "rounds = 20\n",
    "digits = datasets.load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "classifiers = [\n",
    "    (\"SGD\", SGDClassifier()),\n",
    "    (\"ASGD\", SGDClassifier(average=True)),\n",
    "    (\"Perceptron\", Perceptron()),\n",
    "    (\"Passive-Aggressive I\", PassiveAggressiveClassifier(loss='hinge',\n",
    "                                                         C=1.0)),\n",
    "    (\"Passive-Aggressive II\", PassiveAggressiveClassifier(loss='squared_hinge',\n",
    "                                                          C=1.0)),\n",
    "    (\"SAG\", LogisticRegression(solver='sag', tol=1e-1, C=1.e4 / X.shape[0]))\n",
    "]\n",
    "\n",
    "xx = 1. - np.array(heldout)\n",
    "\n",
    "for name, clf in classifiers:\n",
    "    print(\"training %s\" % name)\n",
    "    rng = np.random.RandomState(42)\n",
    "    yy = []\n",
    "    for i in heldout:\n",
    "        yy_ = []\n",
    "        for r in range(rounds):\n",
    "            X_train, X_test, y_train, y_test = \\\n",
    "                train_test_split(X, y, test_size=i, random_state=rng)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            yy_.append(1 - np.mean(y_pred == y_test))\n",
    "        yy.append(np.mean(yy_))\n",
    "    plt.plot(xx, yy, label=name)\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Proportion train\")\n",
    "plt.ylabel(\"Test Error Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD7CAYAAAClvBX1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYYckeQshhB36f+xw/2WaxZ2EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108f49290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "# we create 50 separable points\n",
    "X, Y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n",
    "\n",
    "# fit the model\n",
    "clf = SGDClassifier(loss=\"hinge\", alpha=0.01, n_iter=200, fit_intercept=True)\n",
    "clf.fit(X, Y)\n",
    "\n",
    "# plot the line, the points, and the nearest vectors to the plane\n",
    "xx = np.linspace(-1, 5, 10)\n",
    "yy = np.linspace(-1, 5, 10)\n",
    "\n",
    "X1, X2 = np.meshgrid(xx, yy)\n",
    "Z = np.empty(X1.shape)\n",
    "for (i, j), val in np.ndenumerate(X1):\n",
    "    x1 = val\n",
    "    x2 = X2[i, j]\n",
    "    p = clf.decision_function([[x1, x2]])\n",
    "    Z[i, j] = p[0]\n",
    "levels = [-1.0, 0.0, 1.0]\n",
    "linestyles = ['dashed', 'solid', 'dashed']\n",
    "colors = 'k'\n",
    "plt.contour(X1, X2, Z, levels, colors=colors, linestyles=linestyles)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired)\n",
    "\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using scikit-learn for incremental learning\n",
    "\n",
    "[scikit-learn for incremental learning](http://scikit-learn.org/stable/modules/scaling_strategies.html)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Models: Sequential Learning\n",
    "\n",
    "The learning problem is seen as a game between two players (the learner vs. nature). Learner tries to minimize losses regardless of the move played by the other player, i.e., nature.\n",
    "\n",
    "for $t=1, 2, ...$\n",
    "\n",
    "$\\ \\ \\ \\ $The learner is presented with a new example $x_t \\in X$\n",
    "    \n",
    "$\\ \\ \\ \\ $The learner outputs prediction $p_t$ = $f_t(x_t) \\in Y$\n",
    "    \n",
    "$\\ \\ \\ \\ $Nature looks at output $p_t$ and sends the learner the true lael $y_t \\in Y$\n",
    "    \n",
    "$\\ \\ \\ \\ $The learner suffers $loss(p_t,y_t)$, and updates itsprediction model$\n",
    "\n",
    "We are not making any distributional assumptions about the data.\n",
    "\n",
    "The goal is to perform as well as if we could view the entire sequence of examples ahead of time.\n",
    "\n",
    "$f^\\ast \\in H$ be the hypothesis (sequence of functions) that achieves the least loss for this sequence, i.e. it minimizes  $\\sum_{t = 1}^TV(p_t, y_t)$. We can think of this as the benchmark to beat, i.e., would like the sequence of functions $f_1, f_2, \\ldots$ to have a low loss relative to this. It's customary to call this \"the *regret* on the hypothesis set  $H$\". For sequential learning, the learner is trying to minimize is the regret.\n",
    "\n",
    "$R_T(H) = \\sum_{t = 1}^TV(p_t, y_t) - \\min_{f \\in H} \\sum_{t = 1}^TV(f(x_t), y_t)$\n",
    "\n",
    "\n",
    "We therefore require the learner to be competitive with the best fixed predictor from $H$. In adversarial models, the members of the hypothesis set are also called *experts*.\n",
    "\n",
    "Without additional constraints, one can prove that there is a hypothesis set $H$ such that for any online learning algorithm, the regret is at least linear in  $T$. \n",
    "\n",
    "For learning to be feasible, we would like to obtain a sublinear bound on the regret, so that the average regret goes to  $0$  as  $T \\rightarrow \\infty$. One way to do so is to add the realisability constraint. It states that there exists a fixed hypothesis in $H$ generating the target values. In this case, one can show that the regret $R_T$  is bounded by  $\\log_2 |H|$. However, realisability is usually too strong of an assumption. Another way to bound the regret is to move to the setup of online convex optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online convex optimization\n",
    "\n",
    "In online convex optimization, the hypothesis set and loss functions are assumed to be convex.\n",
    "\n",
    "for $t=1, 2, ...$\n",
    "\n",
    "$\\ \\ \\ \\ $The learner is presented with a new example $x_t \\in X$\n",
    "    \n",
    "$\\ \\ \\ \\ $The learner outputs prediction $p_t$ = $f_t(x_t) \\in Y$, where $Y$ is a fixed convext set.\n",
    "    \n",
    "$\\ \\ \\ \\ $Nature looks at output $p_t$ and sends the learner the true lael $y_t \\in Y$\n",
    "    \n",
    "$\\ \\ \\ \\ $The learner suffers $loss(p_t,y_t)$, and updates itsprediction model$\n",
    "\n",
    "Essentially, we have reduced the problem of competing against the *best* weighted vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow the leader (FTL)\n",
    "\n",
    "The simplest learning rule to try is to select (at the current step) the hypothesis that has the least loss over all past rounds. This algorithm is called *Follow the Leader.*\n",
    "\n",
    "In round  $t$ , set\n",
    "\n",
    "$w_t = \\operatorname*{arg\\,min}_{w \\in S} \\sum_{i=1}^{t-1} v_i(w)$\n",
    "\n",
    "Ties are broken arbitrarily. This method can be looked as a greedy algorithm. For the case of online quadratic optimization (where the loss function is  $v_t(w) = || w - x_t ||_2^2 )$, one can show a regret bound that grows as  $\\log(T)$. Similar bounds cannot be obtained for the *FTL* algorithm for other important families of models like online linear optimization etc. To do so, one modifies FTL by adding *regularization*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow the regularized leader (FTRL)\n",
    "\n",
    "Adding regularization to FTL that is used to stabilise the FTL solutions and obtain better regret bounds. Choose a regularisation function  $R : S \\rightarrow \\mathbb{R}$  and then perform learning as follows:\n",
    "\n",
    "In round  t , set\n",
    "\n",
    "$w_t = \\operatorname*{arg\\,min}_{w \\in S} \\sum_{i=1}^{t-1}v_i(w) + R(w)$\n",
    "\n",
    "Example: consider the case of online linear optmisation, i.e., where nature sends back loss functions of the form  $v_t(w) = \\langle w,z_t \\rangle$. Also, let  $S = \\mathbb{R}^d$. Suppose we choose the regularisation function  $R(w) = \\frac{1}{2 \\eta} ||w||_2^2$  for some positive number  $\\eta$. Then, one can show that the regret minimising iteration becomes:\n",
    "\n",
    "$w_{t+1} = - \\eta \\sum_{i=1}^{t} z_i = w_t - \\eta z_t$\n",
    "\n",
    "Note that this can be rewritten as  $w_{t+1} = w_t - \\eta \\nabla v_t(w_t)$, which looks exactly like online gradient descent. If  $S$  is instead some convex subspace of  $\\mathbb{R}^d$, we would need to project onto  $S$, leading to the modified update rule:\n",
    "\n",
    "$w_{t+1} \\in \\Pi_S(- \\eta \\sum_{i=1}^{t} z_i) = \\Pi_S(\\eta \\theta_{t+1})$\n",
    "\n",
    "This algorithm is known as *lazy projection*, as the vector  $\\theta_{t+1}$  accumulates the gradients. It is also known as *Nesterov’s dual averaging algorithm*. In this scenario of linear loss functions and quadratic regularisation, the regret is bounded by  $O(\\sqrt{T})$, and therefore the average regret goes to $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Refernces:**\n",
    "\n",
    "- [Online Passive-Aggressive Algorithms]((http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf) K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006).\n",
    "\n",
    "- [\"Ad Click Prediction: a View from the Trenches\"](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41159.pdf) H. Brendan McMahan, Gary Holt, D. Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, Sharat Chikkerur, Dan Liu, Martin Wattenberg, Arnar Mar Hrafnkelsson, Tom Boulos, Jeremy Kubica, Google, Inc.\n",
    "\n",
    "- [\"Simple and scalable response prediction for display advertising\"](http://people.csail.mit.edu/romer/papers/TISTRespPredAds.pdf) OLIVIER CHAPELLE, Criteo, EREN MANAVOGLU, Microsoft, ROMER ROSALES, LinkedIn.\n",
    "\n",
    "- [\"Follow-the-Regularized-Leader and Mirror Descent: Equivalent Theorems and L1 Regularization](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwii6pq9n-vLAhWFVyYKHQvZCgYQFggdMAA&url=http%3A%2F%2Fresearch.google.com%2Fpubs%2Fpub37013.html&usg=AFQjCNHaXlvWExXmNPyAWawTfzgsiS7iDA&sig2=Q9J_31pkgozlA0SdtYTNVg) H. Brendan McMahan.\n",
    "\n",
    "- [Web-Scale Bayesian Click-Through Rate Prediction for Sponsored Search Advertising in Microsoft’s Bing Search Engine](http://research.microsoft.com/pubs/122779/AdPredictor%20ICML%202010%20-%20final.pdf?tduid=(6173f2d58ce3ef119c58fef9469ccabc)\n",
    "\n",
    "- [Prediction, learning, and games](http://www.ii.uni.wroc.pl/~lukstafi/pmwiki/uploads/AGT/Prediction_Learning_and_Games.pdf) Nicolò Cesa-Bianchi and Gábor Lugosi.\n",
    "\n",
    "- [On-Line Algorithms in Machine Learning](http://www.cs.cmu.edu/~avrim/Papers/survey.pdf)\n",
    "\n",
    "- [The FTRL Algorithm with Strongly Convex Regularizers](https://courses.cs.washington.edu/courses/cse599s/12sp/scribes/Lecture8.pdf)\n",
    "\n",
    "- [Online Learning and Online Convex Optimization](http://www.cs.huji.ac.il/~shais/papers/OLsurvey.pdf) Shai Shalev-Shwartz\n",
    "\n",
    "- [\"Idiots approach to display advertising\"](http://www.csie.ntu.edu.tw/~r01922136/kaggle-2014-criteo.pdf)\n",
    "\n",
    "- [“Stochastic Gradient Descent”](http://leon.bottou.org/projects/sgd) L. Bottou - Website, 2010.\n",
    "\n",
    "- [“The Tradeoffs of Large Scale Machine Learning”](http://leon.bottou.org/slides/largescale/lstut.pdf) L. Bottou - Website, 2011.\n",
    "\n",
    "- [“Pegasos: Primal estimated sub-gradient solver for svm”](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.74.8513) S. Shalev-Shwartz, Y. Singer, N. Srebro - In Proceedings of ICML ‘07.\n",
    "\n",
    "- [“Stochastic gradient descent training for l1-regularized log-linear models with cumulative penalty”](http://www.aclweb.org/anthology/P/P09/P09-1054.pdf) Y. Tsuruoka, J. Tsujii, S. Ananiadou - In Proceedings of the AFNLP/ACL ‘09.   \n",
    "\n",
    "- [An Introduction to Statistical Learning with applications in R](www.StatLearning.com) James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013), Springer-Verlag, New York. \n",
    "\n",
    "- [scikit-learn](http://scikit-learn.org/stable/)\n",
    "\n",
    "- [Online Learning](https://en.wikipedia.org/wiki/Online_machine_learning).\n",
    "\n",
    "- [Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent).\n",
    "\n",
    "- [scikit-learn](http://scikit-learn.org/stable/)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "# plots within notebook versus launching a separate window\n",
    "%matplotlib inline \n",
    "\n",
    "# create 50 separable points\n",
    "X, Y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n",
    "\n",
    "# fit the model\n",
    "clf = SGDClassifier(loss=\"hinge\", alpha=0.01, n_iter=200, fit_intercept=True)\n",
    "clf.fit(X, Y)\n",
    "\n",
    "# plot the line, the points, and the nearest vectors to the plane\n",
    "xx = np.linspace(-1, 5, 10)\n",
    "yy = np.linspace(-1, 5, 10)\n",
    "\n",
    "X1, X2 = np.meshgrid(xx, yy)\n",
    "Z = np.empty(X1.shape)\n",
    "for (i, j), val in np.ndenumerate(X1):\n",
    "    x1 = val\n",
    "    x2 = X2[i, j]\n",
    "    p = clf.decision_function([[x1, x2]])\n",
    "    Z[i, j] = p[0]\n",
    "levels = [-1.0, 0.0, 1.0]\n",
    "linestyles = ['dashed', 'solid', 'dashed']\n",
    "colors = 'k'\n",
    "plt.contour(X1, X2, Z, levels, colors=colors, linestyles=linestyles)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired)\n",
    "\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online implementation\n",
    "\n",
    "clf = linear_model.SGDClassifier()\n",
    "\n",
    "x1 = some_new_data\n",
    "\n",
    "y1 = the_labels\n",
    "\n",
    "clf.partial_fit(x1,y1)\n",
    "\n",
    "x2 = some_newer_data\n",
    "\n",
    "y2 = the_labels\n",
    "\n",
    "clf.partial_fit(x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = linear_model.SGDClassifier()\n",
    "x1 = some_new_data\n",
    "y1 = the_labels\n",
    "clf.partial_fit(x1,y1)\n",
    "x2 = some_newer_data\n",
    "y2 = the_labels\n",
    "clf.partial_fit(x2,y2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
