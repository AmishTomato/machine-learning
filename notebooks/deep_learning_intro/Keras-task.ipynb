{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting deeper with Keras\n",
    "\n",
    "Jay Urbain\n",
    "\n",
    "* Tensorflow is a powerful and flexible tool, but coding large neural architectures with it is tedious.\n",
    "* There are plenty of deep learning toolkits that work on top of it like Slim, TFLearn, Sonnet, Keras.\n",
    "* Choice is matter of taste and particular task\n",
    "* We'll be using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use preloaded keras datasets and models\n",
    "! mkdir -p ~/.keras/datasets\n",
    "! mkdir -p ~/.keras/models\n",
    "! ln -s $(realpath ../readonly/keras/datasets/*) ~/.keras/datasets/\n",
    "! ln -s $(realpath ../readonly/keras/models/*) ~/.keras/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from preprocessed_mnist import load_dataset\n",
    "import keras\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "y_train,y_val,y_test = map(keras.utils.np_utils.to_categorical,[y_train,y_val,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANBEX4gKMIPBEX4gaAIPxAU4QeC+n8DZI6NXofNrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc4abeafd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pretty keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "s = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "import keras.layers as ll\n",
    "\n",
    "model = Sequential(name=\"mlp\")\n",
    "\n",
    "model.add(ll.InputLayer([28, 28]))\n",
    "\n",
    "model.add(ll.Flatten())\n",
    "\n",
    "# network body\n",
    "model.add(ll.Dense(25))\n",
    "model.add(ll.Activation('linear'))\n",
    "\n",
    "model.add(ll.Dense(25))\n",
    "model.add(ll.Activation('linear'))\n",
    "\n",
    "# output layer: 10 neurons for each class with softmax\n",
    "model.add(ll.Dense(10, activation='softmax'))\n",
    "\n",
    "# categorical_crossentropy is your good old crossentropy\n",
    "# but applied for one-hot-encoded vectors\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                19625     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 20,535\n",
      "Trainable params: 20,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model interface\n",
    "\n",
    "Keras models follow __Scikit-learn__'s interface of fit/predict with some notable extensions. Let's take a tour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 4s - loss: 0.4045 - acc: 0.8830 - val_loss: 0.2915 - val_acc: 0.9207\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 4s - loss: 0.3022 - acc: 0.9136 - val_loss: 0.2804 - val_acc: 0.9230\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 4s - loss: 0.2899 - acc: 0.9176 - val_loss: 0.2715 - val_acc: 0.9259\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 4s - loss: 0.2815 - acc: 0.9214 - val_loss: 0.2799 - val_acc: 0.9218\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 4s - loss: 0.2759 - acc: 0.9226 - val_loss: 0.2697 - val_acc: 0.9274\n"
     ]
    }
   ],
   "source": [
    "# fit(X,y) ships with a neat automatic logging.\n",
    "#          Highly customizable under the hood.\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_val, y_val), epochs=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.19691530e-04,   2.33067796e-02,   8.44826028e-02,\n",
       "          8.43768835e-01,   3.28484589e-06,   1.48870070e-02,\n",
       "          1.89019216e-03,   8.13943046e-09,   3.14378813e-02,\n",
       "          3.66758718e-06],\n",
       "       [  2.27790019e-06,   2.51845086e-05,   6.56424556e-03,\n",
       "          7.39667797e-03,   1.15967309e-03,   7.40212528e-03,\n",
       "          3.55782436e-06,   2.09837594e-06,   9.77138400e-01,\n",
       "          3.05777270e-04]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate probabilities P(y|x)\n",
    "model.predict_proba(X_val[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save trained weights\n",
    "model.save(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9312/10000 [==========================>...] - ETA: 0s\n",
      "Loss, Accuracy =  [0.28471082768142225, 0.9194]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoss, Accuracy = \", model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whoops!\n",
    "So far our model is staggeringly inefficient. There is something wring with it. Guess, what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "import keras.layers as ll\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential(name=\"mlp\")\n",
    "\n",
    "model.add(ll.InputLayer([28, 28]))\n",
    "\n",
    "model.add(ll.Flatten())\n",
    "\n",
    "# network body\n",
    "# model.add(ll.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.001), activity_regularizer=regularizers.l1(0.001) ))\n",
    "model.add(ll.Dense(100, activation='relu'))\n",
    "model.add(ll.Dropout(0.3, noise_shape=None, seed=None))\n",
    "#model.add(ll.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.001), activity_regularizer=regularizers.l1(0.001) ))\n",
    "model.add(ll.Dense(100, activation='relu'))\n",
    "model.add(ll.Dropout(0.3, noise_shape=None, seed=None))\n",
    "\n",
    "# output layer: 10 neurons for each class with softmax\n",
    "model.add(ll.Dense(10, activation='softmax'))\n",
    "\n",
    "# categorical_crossentropy is your good old crossentropy\n",
    "# but applied for one-hot-encoded vectors\n",
    "\n",
    "# opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras + tensorboard\n",
    "\n",
    "Remember the interactive graphs from Tensorboard one notebook ago? \n",
    "\n",
    "Thing is, Keras can use tensorboard to show you a lot of useful information about the learning progress. Just take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r /tmp/tboard/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.4199 - acc: 0.8711 - val_loss: 0.1394 - val_acc: 0.9585\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.2123 - acc: 0.9363 - val_loss: 0.1156 - val_acc: 0.9675\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1698 - acc: 0.9500 - val_loss: 0.0958 - val_acc: 0.9730\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1492 - acc: 0.9548 - val_loss: 0.0940 - val_acc: 0.9746\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1357 - acc: 0.9582 - val_loss: 0.0878 - val_acc: 0.9743\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.1248 - acc: 0.9617 - val_loss: 0.0955 - val_acc: 0.9739\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.1167 - acc: 0.9646 - val_loss: 0.0834 - val_acc: 0.9761\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1094 - acc: 0.9660 - val_loss: 0.0813 - val_acc: 0.9777\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1033 - acc: 0.9678 - val_loss: 0.0814 - val_acc: 0.9771\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0978 - acc: 0.9692 - val_loss: 0.0797 - val_acc: 0.9782\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0950 - acc: 0.9695 - val_loss: 0.0794 - val_acc: 0.9783\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0893 - acc: 0.9720 - val_loss: 0.0835 - val_acc: 0.9787\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0869 - acc: 0.9728 - val_loss: 0.0857 - val_acc: 0.9762\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0864 - acc: 0.9729 - val_loss: 0.0792 - val_acc: 0.9785\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0838 - acc: 0.9740 - val_loss: 0.0786 - val_acc: 0.9790\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0808 - acc: 0.9744 - val_loss: 0.0830 - val_acc: 0.9770\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0794 - acc: 0.9751 - val_loss: 0.0842 - val_acc: 0.9788\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0805 - acc: 0.9746 - val_loss: 0.0764 - val_acc: 0.9797\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0753 - acc: 0.9756 - val_loss: 0.0808 - val_acc: 0.9781\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0747 - acc: 0.9762 - val_loss: 0.0875 - val_acc: 0.9783\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0710 - acc: 0.9776 - val_loss: 0.0814 - val_acc: 0.9800\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0709 - acc: 0.9776 - val_loss: 0.0853 - val_acc: 0.9792\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0732 - acc: 0.9769 - val_loss: 0.0830 - val_acc: 0.9788\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0658 - acc: 0.9789 - val_loss: 0.0761 - val_acc: 0.9800\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0687 - acc: 0.9787 - val_loss: 0.0825 - val_acc: 0.9786\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0689 - acc: 0.9783 - val_loss: 0.0772 - val_acc: 0.9820\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0623 - acc: 0.9805 - val_loss: 0.0819 - val_acc: 0.9795\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0669 - acc: 0.9784 - val_loss: 0.0803 - val_acc: 0.9799\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0629 - acc: 0.9802 - val_loss: 0.0842 - val_acc: 0.9809\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0614 - acc: 0.9807 - val_loss: 0.0839 - val_acc: 0.9803\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0628 - acc: 0.9799 - val_loss: 0.0862 - val_acc: 0.9782\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0616 - acc: 0.9798 - val_loss: 0.0797 - val_acc: 0.9793\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0623 - acc: 0.9806 - val_loss: 0.0787 - val_acc: 0.9796\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0605 - acc: 0.9809 - val_loss: 0.0795 - val_acc: 0.9820\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0586 - acc: 0.9813 - val_loss: 0.0811 - val_acc: 0.9798\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0583 - acc: 0.9817 - val_loss: 0.0908 - val_acc: 0.9783\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0595 - acc: 0.9813 - val_loss: 0.0845 - val_acc: 0.9806\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0598 - acc: 0.9811 - val_loss: 0.0867 - val_acc: 0.9790\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0578 - acc: 0.9815 - val_loss: 0.0855 - val_acc: 0.9786\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0546 - acc: 0.9826 - val_loss: 0.0830 - val_acc: 0.9799\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0570 - acc: 0.9831 - val_loss: 0.0918 - val_acc: 0.9778\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0563 - acc: 0.9814 - val_loss: 0.0861 - val_acc: 0.9810\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0542 - acc: 0.9823 - val_loss: 0.0892 - val_acc: 0.9783\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0556 - acc: 0.9825 - val_loss: 0.0900 - val_acc: 0.9795\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0514 - acc: 0.9834 - val_loss: 0.0899 - val_acc: 0.9803\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0525 - acc: 0.9831 - val_loss: 0.0917 - val_acc: 0.9786\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0526 - acc: 0.9834 - val_loss: 0.0902 - val_acc: 0.9788\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0531 - acc: 0.9834 - val_loss: 0.0912 - val_acc: 0.9794\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0532 - acc: 0.9836 - val_loss: 0.0865 - val_acc: 0.9786\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0506 - acc: 0.9835 - val_loss: 0.0911 - val_acc: 0.9797\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "num_epochs = 50\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "          epochs=num_epochs,\n",
    "          callbacks=[TensorBoard(\"/tmp/tboard\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VNX5+PHPk8kG2QlhRxZB2dcIWKSIC8WtFEutKO6W\n6q+Wr7X6ldrNWu0XlVqXr1XRarUu1I0WV7QWt68bm2wCgiwlrAGSkIUskzy/P85NMoRJMlkmA8nz\nfr3ua2bu+twJzHPPOfeeI6qKMcYYU5+oSAdgjDHm+GAJwxhjTEgsYRhjjAmJJQxjjDEhsYRhjDEm\nJJYwjDHGhMQShmkxIuITkQIROaE5140kEeknIs1+b7qInCUi2wI+bxSRCaGs24hjPSEitzV2+zr2\ne6eI/LW592siJzrSAZhjl4gUBHxsD5QA5d7nH6vqcw3Zn6qWA4nNvW5boKonN8d+RORaYKaqnh6w\n72ubY9+m9bOEYWqlqlU/2N4V7LWq+q/a1heRaFX1t0RsxpiWZ1VSptG8Koe/i8gLIpIPzBSRU0Xk\nMxHJFZHdIvKgiMR460eLiIpIb+/zs97yt0QkX0Q+FZE+DV3XW36OiHwtInki8pCI/J+IXFlL3KHE\n+GMR2SwiOSLyYMC2PhH5k4gcEJEtwJQ6vp9fisiCGvMeFpH7vPfXish673y+8a7+a9tXloic7r1v\nLyJ/82JbB4yuse6vRGSLt991IvJdb/5Q4H+BCV513/6A7/b2gO2v8879gIj8Q0S6hvLd1EdEpnnx\n5IrIv0Xk5IBlt4nILhE5JCIbAs51nIis8ObvFZF7Qz2eCQNVtcmmeidgG3BWjXl3AqXABbiLj3bA\nKcBYXOm1L/A1cIO3fjSgQG/v87PAfiATiAH+DjzbiHU7AfnAVG/ZTUAZcGUt5xJKjP8EUoDewMHK\ncwduANYBPYB04EP33yjocfoCBUBCwL73AZne5wu8dQQ4AzgMDPOWnQVsC9hXFnC6934e8D6QBvQC\nvqqx7kVAV+9vcokXQ2dv2bXA+zXifBa43Xs/2YtxBBAP/Bn4dyjfTZDzvxP4q/d+oBfHGd7f6DZg\no/d+MLAd6OKt2wfo671fCszw3icBYyP9f6EtT1bCME31saq+pqoVqnpYVZeq6ueq6lfVLcB8YGId\n27+sqstUtQx4DvdD1dB1zwe+VNV/esv+hEsuQYUY4/+oap6qbsP9OFce6yLgT6qapaoHgLl1HGcL\nsBaXyADOBnJUdZm3/DVV3aLOv4H3gKAN2zVcBNypqjmquh1Xagg87ouqutv7mzyPS/aZIewX4FLg\nCVX9UlWLgTnARBHpEbBObd9NXS4GFqnqv72/0Vxc0hkL+HHJabBXrbnV++7AJf7+IpKuqvmq+nmI\n52HCwBKGaaodgR9EZICIvCEie0TkEHAH0LGO7fcEvC+i7obu2tbtFhiHqiruijyoEGMM6Vi4K+O6\nPA/M8N5f4n2ujON8EflcRA6KSC7u6r6u76pS17piEJErRWSVV/WTCwwIcb/gzq9qf6p6CMgBuges\n05C/WW37rcD9jbqr6kbg57i/wz6virOLt+pVwCBgo4h8ISLnhngeJgwsYZimqnlL6WO4q+p+qpoM\n/AZX5RJOu3FVRACIiHDkD1xNTYlxN9Az4HN9t/2+CJwlIt1xJY3nvRjbAS8D/4OrLkoF3gkxjj21\nxSAifYFHgOuBdG+/GwL2W98twLtw1VyV+0vCVX3tDCGuhuw3Cvc32wmgqs+q6nhcdZQP972gqhtV\n9WJcteMfgVdEJL6JsZhGsoRhmlsSkAcUishA4MctcMzXgVEicoGIRAP/BWSEKcYXgRtFpLuIpAO3\n1rWyqu4BPgb+CmxU1U3eojggFsgGykXkfODMBsRwm4ikintO5YaAZYm4pJCNy50/wpUwKu0FelQ2\n8gfxAnCNiAwTkTjcD/dHqlpria0BMX9XRE73jn0Lrt3pcxEZKCKTvOMd9qYK3AlcJiIdvRJJnndu\nFU2MxTSSJQzT3H4OXIH7MXgM1zgdVqq6F/ghcB9wADgRWIl7bqS5Y3wE19awBtcg+3II2zyPa8Su\nqo5S1VzgZ8BCXMPxdFziC8VvcSWdbcBbwDMB+10NPAR84a1zMhBY7/8usAnYKyKBVUuV27+Nqxpa\n6G1/Aq5do0lUdR3uO38El8ymAN/12jPigHtw7U57cCWaX3qbngusF3cX3jzgh6pa2tR4TOOIq+41\npvUQER+uCmS6qn4U6XiMaS2shGFaBRGZ4lXRxAG/xt1d80WEwzKmVbGEYVqL04AtuOqO7wDTVLW2\nKiljTCNYlZQxxpiQWAnDGGNMSFpV54MdO3bU3r17RzoMY4w5bixfvny/qtZ1G3qVVpUwevfuzbJl\nyyIdhjHGHDdEpL7eCqpYlZQxxpiQWMIwxhgTEksYxhhjQtKq2jCMMS2rrKyMrKwsiouLIx2KqUd8\nfDw9evQgJqa2bsTqZwnDGNNoWVlZJCUl0bt3b1wnweZYpKocOHCArKws+vTpU/8GtbAqKWNMoxUX\nF5Oenm7J4hgnIqSnpze5JGgJwxjTJJYsjg/N8XeyhAFs2/Z7Dh5cHOkwjDHmmGYJA9ix414OHnw7\n0mEYYxrgwIEDjBgxghEjRtClSxe6d+9e9bm0NLQhM6666io2btxY5zoPP/wwzz33XHOEzGmnncaX\nX37ZLPuKBGv0Bny+ZPz+Q5EOwxjTAOnp6VU/vrfffjuJiYncfPPNR6yjqqgqUVHBr42feuqpeo/z\nk5/8pOnBthJWwgCio1MoL7eEYUxrsHnzZgYNGsSll17K4MGD2b17N7NmzSIzM5PBgwdzxx13VK1b\necXv9/tJTU1lzpw5DB8+nFNPPZV9+/YB8Ktf/Yr777+/av05c+YwZswYTj75ZD755BMACgsL+f73\nv8+gQYOYPn06mZmZ9ZYknn32WYYOHcqQIUO47bbbAPD7/Vx22WVV8x988EEA/vSnPzFo0CCGDRvG\nzJkzm/07C5WVMIDo6GT8/rxIh2HMcW3TphspKGje6pbExBH0739/g7fbsGEDzzzzDJmZmQDMnTuX\nDh064Pf7mTRpEtOnT2fQoEFHbJOXl8fEiROZO3cuN910E08++SRz5sw5at+qyhdffMGiRYu44447\nePvtt3nooYfo0qULr7zyCqtWrWLUqFF1xpeVlcWvfvUrli1bRkpKCmeddRavv/46GRkZ7N+/nzVr\n1gCQm5sLwD333MP27duJjY2tmhcJVsLAqqSMaW1OPPHEqmQB8MILLzBq1ChGjRrF+vXr+eqrr47a\npl27dpxzzjkAjB49mm3btgXd94UXXnjUOh9//DEXX3wxAMOHD2fw4MF1xvf5559zxhln0LFjR2Ji\nYrjkkkv48MMP6devHxs3bmT27NksXryYlJQUAAYPHszMmTN57rnnmvTgXVNZCQNXJVVSsiPSYRhz\nXGtMSSBcEhISqt5v2rSJBx54gC+++ILU1FRmzpwZ9HmE2NjYqvc+nw+/3x9033FxcfWu01jp6ems\nXr2at956i4cffphXXnmF+fPns3jxYj744AMWLVrEH/7wB1avXo3P52vWY4fCShhUljCsSsqY1ujQ\noUMkJSWRnJzM7t27Wby4+W+hHz9+PC+++CIAa9asCVqCCTR27FiWLFnCgQMH8Pv9LFiwgIkTJ5Kd\nnY2q8oMf/IA77riDFStWUF5eTlZWFmeccQb33HMP+/fvp6ioqNnPIRRWwsC1YVijtzGt06hRoxg0\naBADBgygV69ejB8/vtmP8dOf/pTLL7+cQYMGVU2V1UnB9OjRg9///vecfvrpqCoXXHAB5513HitW\nrOCaa65BVRER7r77bvx+P5dccgn5+flUVFRw8803k5SU1OznEIqwjuktIlOABwAf8ISqzq1lvVOA\nT4GLVfXlhmwbKDMzUxszgNK2bb9j27bbmTjRj0jLF/OMOV6tX7+egQMHRjqMiPP7/fj9fuLj49m0\naROTJ09m06ZNREcfW9fkwf5eIrJcVTNr2eQIYTsbcb+8DwNnA1nAUhFZpKpfBVnvbuCdhm7bXHy+\nZADKywuIjq79qsAYY4IpKCjgzDPPxO/3o6o89thjx1yyaA7hPKMxwGZV3QIgIguAqUDNH/2fAq8A\npzRi22YRHe0Sht+fZwnDGNNgqampLF++PNJhhF04G727A4G3HmV586qISHdgGvBIQ7cN2McsEVkm\nIsuys7MbFWhlCcNurTXGmNpF+i6p+4FbVbWisTtQ1fmqmqmqmRkZGY3aR2Wpwhq+jTGmduGsktoJ\n9Az43MObFygTWOB1u9sROFdE/CFu22yqSxh2a60xxtQmnAljKdBfRPrgfuwvBi4JXEFVq4Z+EpG/\nAq+r6j9EJLq+bZtTZRuGlTCMMaZ2YauSUlU/cAOwGFgPvKiq60TkOhG5rjHbhivWyiopa8Mw5vgy\nadKkox7Eu//++7n++uvr3C4xMRGAXbt2MX369KDrnH766dR3m/79999/xEN05557brP09XT77bcz\nb968Ju+nuYW1DUNV31TVk1T1RFW9y5v3qKo+GmTdKyufwaht23CxKiljjk8zZsxgwYIFR8xbsGAB\nM2bMCGn7bt268fLLL9e/Yi1qJow333yT1NTURu/vWBfpRu9jgs+XAIhVSRlznJk+fTpvvPFG1YBJ\n27ZtY9euXUyYMKHq2YhRo0YxdOhQ/vnPfx61/bZt2xgyZAgAhw8f5uKLL2bgwIFMmzaNw4cPV613\n/fXXV3WP/tvf/haABx98kF27djFp0iQmTZoEQO/evdm/fz8A9913H0OGDGHIkCFV3aNv27aNgQMH\n8qMf/YjBgwczefLkI44TzJdffsm4ceMYNmwY06ZNIycnp+r4lV2eV3Z8+MEHH1QNIjVy5Ejy8/Mb\n/d0G0/qeLGkEkSjrsdaYJrrxRmjuweRGjID76+jTsEOHDowZM4a33nqLqVOnsmDBAi666CJEhPj4\neBYuXEhycjL79+9n3LhxfPe73611bOtHHnmE9u3bs379elavXn1EF+V33XUXHTp0oLy8nDPPPJPV\nq1cze/Zs7rvvPpYsWULHjh2P2Nfy5ct56qmn+Pzzz1FVxo4dy8SJE0lLS2PTpk288MILPP7441x0\n0UW88sordY5xcfnll/PQQw8xceJEfvOb3/C73/2O+++/n7lz57J161bi4uKqqsHmzZvHww8/zPjx\n4ykoKCA+Pr4B33b9rIThcf1JWZWUMcebwGqpwOooVeW2225j2LBhnHXWWezcuZO9e/fWup8PP/yw\n6od72LBhDBs2rGrZiy++yKhRoxg5ciTr1q2rt3PBjz/+mGnTppGQkEBiYiIXXnghH330EQB9+vRh\nxIgRQN3dqIMboyM3N5eJEycCcMUVV/Dhhx9WxXjppZfy7LPPVj1VPn78eG666SYefPBBcnNzm/1p\ncytheKyEYUzT1FUSCKepU6fys5/9jBUrVlBUVMTo0aMBeO6558jOzmb58uXExMTQu3fvoN2a12fr\n1q3MmzePpUuXkpaWxpVXXtmo/VSq7B4dXBfp9VVJ1eaNN97gww8/5LXXXuOuu+5izZo1zJkzh/PO\nO48333yT8ePHs3jxYgYMGNDoWGuyEobHeqw15viUmJjIpEmTuPrqq49o7M7Ly6NTp07ExMSwZMkS\ntm/fXud+vv3tb/P8888DsHbtWlavXg247tETEhJISUlh7969vPXWW1XbJCUlBW0nmDBhAv/4xz8o\nKiqisLCQhQsXMmHChAafW0pKCmlpaVWlk7/97W9MnDiRiooKduzYwaRJk7j77rvJy8ujoKCAb775\nhqFDh3LrrbdyyimnsGHDhgYfsy5WwvBER6dQVnYw0mEYYxphxowZTJs27Yg7pi699FIuuOAChg4d\nSmZmZr1X2tdffz1XXXUVAwcOZODAgVUlleHDhzNy5EgGDBhAz549j+gefdasWUyZMoVu3bqxZMmS\nqvmjRo3iyiuvZMyYMQBce+21jBw5ss7qp9o8/fTTXHfddRQVFdG3b1+eeuopysvLmTlzJnl5eagq\ns2fPJjU1lV//+tcsWbKEqKgoBg8eXDWCYHMJa/fmLa2x3ZsDrFv3QwoKVjF2bPNmZGNaM+ve/PjS\n1O7NrUrKY1VSxhhTN0sYHp8vxRq9jTGmDpYwPNHRyVRUFFJR0byDuhvT2rWmau3WrDn+TpYwPNWj\n7jXvk5HGtGbx8fEcOHDAksYxTlU5cOBAkx/ks7ukPIFjYsTEpEU4GmOODz169CArK4vGDl5mWk58\nfDw9evRo0j4sYXgCh2k1xoQmJiaGPn361L+iaRWsSspjw7QaY0zdLGF4bJhWY4ypmyUMj42JYYwx\ndbOE4bFhWo0xpm6WMDzWhmGMMXULa8IQkSkislFENovInCDLp4rIahH5UkSWichpAcu2iciaymXh\njBMqR92LsiopY4ypRdhuqxURH/AwcDaQBSwVkUWqGjjyyHvAIlVVERkGvAgEdik5SVX3hyvGGvFa\nf1LGGFOHcJYwxgCbVXWLqpYCC4CpgSuoaoFWPyKaAET0cVEbRMkYY2oXzoTRHdgR8DnLm3cEEZkm\nIhuAN4CrAxYp8C8RWS4is2o7iIjM8qqzljX1adPo6BQrYRhjTC0i3uitqgtVdQDwPeD3AYtOU9UR\nwDnAT0Tk27VsP19VM1U1MyMjo0mxuBKGtWEYY0ww4UwYO4GeAZ97ePOCUtUPgb4i0tH7vNN73Qcs\nxFVxhZW1YRhjTO3CmTCWAv1FpI+IxAIXA4sCVxCRfiIi3vtRQBxwQEQSRCTJm58ATAbWhjFWwFVJ\nWRuGMcYEF7a7pFTVLyI3AIsBH/Ckqq4Tkeu85Y8C3wcuF5Ey4DDwQ++Oqc7AQi+XRAPPq+rb4Yq1\nklVJGWNM7cLaW62qvgm8WWPeowHv7wbuDrLdFmB4OGMLxqqkjDGmdhFv9D6W+HzJVFQcpqKiLNKh\nGGPMMccSRgDrsdYYY2pnCSOA9SdljDG1s4QRwHqsNcaY2lnCCFBZJWV3ShljzNEsYQSwKiljjKmd\nJYwAViVljDG1s4QRwOezKiljjKmNJYwAVsIwxpjaWcIIEBXVDvBZG4YxxgRhCSOAjbpnjDG1s4RR\ng+ux1towjDGmJksYNdgwrcYYE5wljBqsSsoYY4KzhFGDz2dVUsYYE4wljBqshGGMMcFZwqjB2jCM\nMSa4sCYMEZkiIhtFZLOIzAmyfKqIrBaRL0VkmYicFuq24WJ3SRljTHBhSxgi4gMeBs4BBgEzRGRQ\njdXeA4ar6gjgauCJBmwbFtHRyaiWUFFR0hKHM8aY40Y4SxhjgM2qukVVS4EFwNTAFVS1QFXV+5gA\naKjbhkt1j7X5LXE4Y4w5boQzYXQHdgR8zvLmHUFEponIBuANXCkj5G297Wd51VnLsrOzmxx0dX9S\nVi1ljDGBIt7oraoLVXUA8D3g943Yfr6qZqpqZkZGRpPjqe6x1hq+jTEmUDgTxk6gZ8DnHt68oFT1\nQ6CviHRs6LbNyXqsNcaY4MKZMJYC/UWkj4jEAhcDiwJXEJF+IiLe+1FAHHAglG3DpboNw6qkjDEm\nUHS4dqyqfhG5AVgM+IAnVXWdiFznLX8U+D5wuYiUAYeBH3qN4EG3DVesgarH9bYShjHGBApbwgBQ\n1TeBN2vMezTg/d3A3aFu2xKsSsoYY4KLeKP3saa6SsoShjHGBLKEUUNUVDwiMXZbrTHG1GAJowYR\nsf6kjDEmCEsYQViPtcYYczRLGEG4EoZVSRljTCBLGEG4HmuthGGMMYEsYQRhVVLGGHM0SxhBWJWU\nMcYczRJGENHRKVbCMMaYGixhBGG31RpjzNEsYQThRt0rpby8ONKhGGPMMcMSRhCVHRBatZQxxlSz\nhBGE9SdljDFHs4QRhA3TaowxR7OEEYSVMIwx5miWMIKwNgxjjDmaJYwgrIRhjDFHs4QRRGUbhj3t\nbYwx1cKaMERkiohsFJHNIjInyPJLRWS1iKwRkU9EZHjAsm3e/C9FZFk446zJqqSMMeZoYRvTW0R8\nwMPA2UAWsFREFqnqVwGrbQUmqmqOiJwDzAfGBiyfpKr7wxVjbaKi4hCJtSopY4wJEM4Sxhhgs6pu\nUdVSYAEwNXAFVf1EVXO8j58BPcIYT4O4HmutSsoYYyqFlDBE5EQRifPeny4is0UktZ7NugM7Aj5n\nefNqcw3wVsBnBf4lIstFZFYdsc0SkWUisiw7O7uekELn89mYGMYYEyjUEsYrQLmI9MNVG/UEnm+u\nIERkEi5h3Bow+zRVHQGcA/xERL4dbFtVna+qmaqamZGR0Vwh2ZgYxhhTQ6gJo0JV/cA04CFVvQXo\nWs82O3GJpVIPb94RRGQY8AQwVVUPVM5X1Z3e6z5gIa6Kq8XYmBjGGHOkUBNGmYjMAK4AXvfmxdSz\nzVKgv4j0EZFY4GJgUeAKInIC8Cpwmap+HTA/QUSSKt8Dk4G1IcbaLGyYVmOMOVKod0ldBVwH3KWq\nW0WkD/C3ujZQVb+I3AAsBnzAk6q6TkSu85Y/CvwGSAf+LCIAflXNBDoDC7150cDzqvp2g8+uCaxK\nyhhjjhRSwvBuhZ0NICJpQJKq3h3Cdm8Cb9aY92jA+2uBa4NstwUYXnN+S7IqKWOMOVKod0m9LyLJ\nItIBWAE8LiL3hTe0yKosYahqpEMxxphjQqhtGCmqegi4EHhGVccCZ4UvrMjz+VJQ9VNRYaPuGWMM\nhJ4wokWkK3AR1Y3erVr1mBjWjmGMMRB6wrgD13j9jaouFZG+wKbwhRV51T3WWjuGMcZA6I3eLwEv\nBXzeAnw/XEEdCyo7ILRba40xxgm10buHiCwUkX3e9IqIHDP9PoWDVUkZY8yRQq2Segr30F03b3rN\nm9dqWZWUMcYcKdSEkaGqT6mq35v+CjRfx03HIBsTwxhjjhRqwjggIjNFxOdNM4ED9W51HLNhWo0x\n5kihJoyrcbfU7gF2A9OBK8MU0zEhOjoJsCopY4ypFFLCUNXtqvpdVc1Q1U6q+j1a+V1SbtS9OKuS\nMsYYT1NG3Lup2aI4RlmPtcYYU60pCUOaLYpjlA3Taowx1ZqSMFp9r3yux1orYRhjDNTzpLeI5BM8\nMQjQLiwRHUNiYztRUvKfSIdhjDHHhDpLGKqapKrJQaYkVQ118KXjVmrq6RQWrqWkZHekQzHGmIhr\nSpVUq5eWNhmAnJx/RTgSY4yJPEsYdUhMHE5MTAY5Oe9EOhRjjIm4sCYMEZkiIhtFZLOIzAmy/FIR\nWS0ia0TkExEZHuq2LUEkirS0szl48F1UKyIRgjHGHDPCljBExAc8DJwDDAJmiMigGqttBSaq6lDg\n98D8BmzbItLSzqasbC+FhWsicXhjjDlmhLOEMQbYrKpbVLUUWABMDVxBVT9R1Rzv42dAj1C3bSkd\nOpwNwMGDVi1ljGnbwpkwugM7Aj5nefNqcw3wVkO3FZFZIrJMRJZlZ2c3Idzg4uK60779YHJy3m32\nfRtjzPHkmGj0FpFJuIRxa0O3VdX5qpqpqpkZGeHpcb1Dh8nk5n5IefnhsOzfGGOOB+FMGDuBngGf\ne3jzjiAiw4AngKmqeqAh27aUtLTJqJaQl/dRpEIwxpiIC2fCWAr0F5E+IhILXIwbta+KiJwAvApc\npqpfN2TblpSa+m1EYq0dwxjTpoXtaW1V9YvIDcBiwAc8qarrROQ6b/mjwG+AdODPIgLg96qXgm4b\nrljr4/O1JyVlgj2PYYxp00S19fQhmJmZqcuWLQvLvv/zn3vYsuVWTj11F3FxXcNyDGOMaWkislxV\nM0NZ95ho9D4eVHcTYndLGWPaJksYIUpMHEZMTCdrxzDGtFmWMEJU2U1ITo51E2KMaZssYTRAhw6T\nKSvbR0HB6kiHYowxLc4SRgOkpbluQuxuKWNMW2QJowHi4rqSkDDEGr6NMW2SJYwGSkubTG7uR5SX\nF0U6FGOMaVGWMBqoQwfrJsQY0zZZwmiglJQJiMTZ7bXGmDbHEkYD+XztSU2dwMGDb9OanpI3xpj6\nWMJohIyM6RQVfcWBA29EOhRjjGkxljAaoUuXq2nX7iS++eZmKirKIh2OMca0CEsYjRAVFcOJJ87j\n8OGN7Nr1WKTDMcaYFmEJo5HS088nNfVMtm37LWVlOfVvYIwxxzlLGI0kIvTr90f8/hy2b78z0uEY\nY0zYWcJogsTE4XTpcjU7dz5EUdHmSIdjjDFhZQmjifr0+T0isWzZcmukQzHGmLCyhNFEcXFd6dXr\nF+zf/yq5uR9EOhxjjAmbsCYMEZkiIhtFZLOIzAmyfICIfCoiJSJyc41l20RkjYh8KSLhGXe1mfTo\ncRNxcT3ZvPkmGyvDGNNqhS1hiIgPeBg4BxgEzBCRQTVWOwjMBubVsptJqjoi1PFmI8Xna0ffvv9D\nQcEK9u59NtLhGGNMWISzhDEG2KyqW1S1FFgATA1cQVX3qepS4Lh/+q1TpxkkJY1hy5Zf4PcfinQ4\nxhjT7MKZMLoDOwI+Z3nzQqXAv0RkuYjMqm0lEZklIstEZFl2dnYjQ206kSj69XuAsrJ9rFv3A3sC\n3BjT6hzLjd6nqeoIXJXWT0Tk28FWUtX5qpqpqpkZGRktG2ENKSnjOOmkR8nJeYdNm35qnRMaY1qV\ncCaMnUDPgM89vHkhUdWd3us+YCGuiuuY17XrNZxwwhx2736MHTv+GOlwjDGm2YQzYSwF+otIHxGJ\nBS4GFoWyoYgkiEhS5XtgMrA2bJE2sz597iIj4wds2XIL2dmvRDocY4xpFtHh2rGq+kXkBmAx4AOe\nVNV1InKdt/xREekCLAOSgQoRuRF3R1VHYKGIVMb4vKq+HZ444a23oHdvGFTzHq5GEoliwICnKSnZ\nwfr1M4mL60Fy8tjm2bkxxkSItKZ69szMTF22rGGPbBw6BD17wtlnw8svN288paX7WLFiHOXlhYwa\n9Tnt2vVu3gMYY0wTicjyUB9dOJYbvVtEcjLMng2vvALr1jXvvmNjOzF06BuolrJmzXnWq60x5rjW\n5hMGwI03QkIC/OEPzb/vhISBDB78KocPb2LVqjMpLd3X/AcxxpgWYAkDSE+H//f/YMEC2LSp+fef\nljaJIUMz1V6GAAAblUlEQVQWUVS0gZUrJ1BcvKP+jYwx5hhjCcPz859DXFx4ShkA6elTGDbsHUpL\n97By5WkUFX0dngMZY0yYWMLwdO4Ms2bB3/4GW7eG5xipqacxYsT7VFQcZuXKCRQUrArPgYwxJgws\nYQS45Rbw+WDu3PAdIylpJCNHfkRUVBwrV04kL++T8B3MGGOakSWMAN27wzXXwFNPwY4wNjO0b38y\nI0d+TGxsZ1atOpv9+0N6ntEYYyLKEkYNt97qHua7557wHic+/gRGjvyI9u0HsHbtVL7++nrKywvD\ne1BjjGkCSxg19OoFV1wBjz8Ou3eH91ixsZ0YNeoTeva8mV27HmPZspEcOvR5eA9qjDGNZAkjiF/8\nAvx+mFfbsE7NKCoqjhNPvJfhw/9NRUUJK1aMZ+vW2617dGPMMccSRhAnngiXXAKPPgotNcRGWtrp\nnHLKajp3voTt239nt94aY445ljBqcdttcPgw3Hdfyx0zOjqFgQOfYdCgFzl8eBPLlg1n+/Y/UFFR\n2nJBGGNMLSxh1GLAAJgxA+6/H7Zvb9ljd+r0A045ZS3p6eezdesvWb58tN1+a4yJOEsYdZg7F6Ki\n3FPgLS0urhuDB7/EkCGv4ffnsXLlaXz99fWUleW2fDDGGIMljDr17Omqpl55Bd57LzIxdOx4Pqec\n8hU9etzIrl3zWbp0IPv2vWjDvxpjWlybHw+jPsXFMHgwxMfDl19CTEyz7r5B8vOXs3HjLAoKVpCU\nNJa+feeSlnZ65AIyxhz3bDyMZhQfD3/6E3z1Ffz5z5GNJSlpNKNGfc7JJ/+F0tKdrFo1iVWrppCf\nvzKygRlj2oSwJgwRmSIiG0Vks4jMCbJ8gIh8KiIlInJzQ7ZtSRdcAN/5Dvz2t7AvwsNZREVF07Xr\n1YwZs4kTT5xHfv5Sli8fxVdfzaCoaHNkgzPGtGphSxgi4gMeBs7BjdM9Q0Rqjpp9EJgNzGvEti1G\nBB54AAoLXZvGscDni6dnz58zbtwWTjjhl+zfv4ilSweyfv0VFBauj3R4xphWKJwljDHAZlXdoqql\nwAJgauAKqrpPVZcCNR9rrnfblnbyyW5kviefhKVLIxnJkaKjU+jb907Gjv2Gbt1+Qnb2yyxdOpi1\nay/k0KFjKFBjzHEvnAmjOxDY52uWN69ZtxWRWSKyTESWZYf5sexf/9qNm/HTn0JFRVgP1WBxcV3o\n3/9+xo3bTq9evyI3dwkrVoxh1aqzycn5t91VZYxpsuO+0VtV56tqpqpmZmRkhPVYyclw993w+efw\nzDNhPVSjxcZ2pE+fOxg3bjt9+95DYeFaVq06k08+6czatReyY8d9HDr0hfVVZYxpsOgw7nsn0DPg\ncw9vXri3DauZM10fU9dc44ZzHTjQPRVeOQ0aBCkpoe1r3TpXzTVhgiu9iDRfnNHRyZxwwi107/5T\nsrNfJCfn3+Tlfcz+/QsBiIpqR3LyODIyvk+XLtfg88U338GNMa1SOBPGUqC/iPTB/dhfDFzSAtuG\nVVQUvPSSSxobNsD69fD221Dqdffk87lk8pvfuAGZgikrc+Nt3HGH+/yvf7lk8etfN3+8Pl88Xbpc\nTpculwNQUrKbvLz/Iy/vY3Jzl7Bp0w1s334XPXv+N926zcLna9/8QRhjWoWwPrgnIucC9wM+4ElV\nvUtErgNQ1UdFpAuwDEgGKoACYJCqHgq2bX3HC8eDe6Hw+9044Bs2uOTx+OMuccye7QZk6tChet3V\nq+Gqq2DFCvjBD+DBB906zzwDf/wj3HRTy8WtquTmfsD27XeQm7uEmJhO9Ox5M926XU90dGLLBWJa\nvT174OuvXWm6OUvS9Skvd138vPEG3HADXHQRRIfpMrmiArKy3HkGTvv3u14jeveGPn3c1Lu3u6A8\ndMjdql857d0LBw7Aqae62/nri7WsDF57zf32NPYOzoY8uIeqtppp9OjReizYskX1sstURVRTUlTv\nuks1J0f19ttVY2JUMzJUX3qpev2yMtUf/EAVVB95JDIx5+R8pF9+OVmXLEE/+ihdN2++VbOzF2lJ\nyZ7IBGRajc8+U+3Sxf37njDBfW4Je/eqnn22O27l8fv1U/3LX1RLS4NvU1bm4rvnHtWf/Uz1iitU\nL7hAdfx41UGD3H46dFBNT1ft2NH9X+7USbVzZ9V27dwxKqf27VVHjHAxDBx49PLapuho99qtm+pv\nfqO6Y8fRcW7ZonrbbdXn1aePanFx474nYJmG+BtrXYOE0Zo18MtfuisAn89d7cyY4UoVHTseuW5p\nKVx4obsSevppuPzyyMScl/cZ27ffycGDbwPlAMTF9SI5eQxJSWNITBxOdHQyUVHtiIpqj89X+ZpA\nVFRsZIIOorDQfY8nnADnndeyV7Wm2gsvuBJ1t27w4x+74QL27XOl6z/8Afr1C75dRQX85z/uRpO0\ntIb//T76CC6+2F2t/+//wtVXwz/+AXfeCStXun8Xt97qYtu2zVULv/cevP8+5OW5fSQmutqBDh1c\nDJWvcXHBf+oTE+Gkk6qnbt2OjFvVnfvWrW7atQtSU6FTpyOnuDh4801X7f32224fF1zgvr/Dh+Gx\nx+Ddd938c89186dMaXzJqSElDEsYLeCTT9zzG+efD9/7Xu3rFRe7dZYsgb//HaZPb7kYayovL6Kg\nYCV5eZ+zfv1WVq4s5auvulNYmML3v/8A3bptrbGFkJAwmOTkb5GSMp6UlPHEx/dFWviXuqICnn8e\n5syBnd5tEmPHuh+nM86ofTtVV024cSMMHepuYIhkv2HNobjYVYGuWAHLl7upXTv4/e/r/i6aQ0WF\n6xnhzjtdNdSrr7qLpPx8V/U6bx6UlMB118F//7f7IV250k1ffgmrVrmkD+4HtFs3V4VT+TpoEIwb\n52468fmOPO68ea56pk8f1944YkT1clV46y33HXz2mfsbl3k3DPbpA2eeCWedBZMmuR/vSNu61VVx\n/+Uv1b1M9OgB117rkmDPnnVvHwpLGMexwkLXDcnnn7srozPOgL59j/xPEU5lZfDOO+5qq/I/b67X\no3pUlBId7f69/OhHm5g9+0sSE/MoLy/C788hP/8L8vI+pbzcXaLFxHQmJeVbpKZOJDX1DBISBiPi\n7uTetw/WrnXjpu/e7a62Kt937Aj33uv+AzfEp5+6u86++AIyM90P06ZN8LvfwY4d7ru86y73QwPV\nSeKll+DFF91/zkpxcS5xjBwJo0bBmDHu9VjwzTcu5kWL3L+X2FgXb2ysm2Ji3PmuW+fa18BdGY8e\n7b6P7dvdFeu997oHUptbYaErIb/6qrsB5M9/dnEF2rPH/V0ef9yVvCslJbkf+BEjYMgQKCpy/zZ2\n7qx+3bnTza9cf8wYd1EwZgw88QS8/rorwTzxhCuhBKPqLsxefRWGD3eJom/f5v8umktpqat9iI+H\nyZOb9/fAEsZxLi8Pzj67+ony9u1dj7lDh7rpxBPd3VoVFe4ffuVrVJRrTOvXDxISQj+eqktQzz7r\nSjb797sr0WHD3A/miBHudehQyMmBX/0K/vpXSE93/+lnzaouDqtWUFj4FYcO/Z93N9b/UVy8BQCR\nrqxZcyOvvXYR773Xi/Ly6tJH+/bQtaubVq1y53Tvva64HVXP00I7drjqhRdecNvPnetuf67crrjY\nFeP/8AeXqC64wF2hvvQSbNniYj/rLPcjM3q0S2SVV7srV7pzBle19cAD7vuvywcfuCvY1FR3E8O3\nvlX3+sXF8PLLLuH16uX+fv36ueNU/h23bq1ObMuXu3ljxrgr7tJSd7Ve+VpS4h4wHT26eurVy1Vh\nFBe7c7jrLle9cf31riSQnl53jKHw+10J7bLL3N9w3jyXwOsqZG7cCAsXuvMdMcL9aNf391Z1ie/z\nz10p4bPP3PHKy12yvO8++MlPrBoyVJYwWoGyMnd1v3q1awupnEJ9mL1bN+jfv3pKTXVXofHx1a8x\nMa6u99ln3VVrfDxMnQqXXupKOTWvCgOtXOl+DN9/31UL3H23u6pPTnY//oH/WVev3sX8+Qf4+997\nsn9/Kmlpe/jOd55m7NiP6N49iu7d25GenkG7dr2Jj+/F7t0dmT37JD78sDvjxm3k9tv/SMeOq1At\npXPny+na9VpEknjvPXjqKfeDIwI33+wSR2ItN3gVFLj2o3vuce8rk8T3vlf7D6aqq0t/6SWXHMvK\n3DHmzHFJNdBXX7llr7/uqk2KilyyOfVUuOUW+O53j7wy/OYbl8ieesol6fbtq6+cK3Xt6v52673u\nwcaOdXf6TJ/u6uEba98+lyjmz3d/s5//3CXRwLr0lJTqv2NJCRw86NoEKqft2905bN7sXrdtc0kj\nKQkWLHD16y2lqMiVFrt0qb1dxARnCaMV27vX/UcVcVNUVPVrWZm7Ev36a3cFVjnVlWREXFXNzJmu\n0b22Inwwqq5a5Oab3Y9Gpagot5/kZJecNm1yP5Tnnw9XXaWcfvpmCgv/TWHhOoqLt1FcvJ3i4u1V\nVVmV+3799R/xyCN/RCSKn/3sCaZNW8CGDdksXvxj3n33R+zZk0paGlxyiftB7tUrtLgLC913lZoa\n+rmCqxK55RbXRtK7t7tSv+ACV73y29+6eubERFd/Pnu2KyU9+aTrHn/rVvdDdtNNLplXNmj6fC6R\nXH+9qxbJz6/+Ea78Id6zx9WpT5/ujtuc1q51f7/Fi49eFhPjGnoLCqrbE2pKSXElocDprLOaP04T\nPpYwzBHy891UXOyuFANf+/ev/QHDUFXWr+7b5+4rD5zy813VyeWXu6u/upSV5VJSsp3y8gJiY7sR\nG9uFrKx2XHutu4ulVy+XLKOiKsjMfIdzznmaqVPj6dfvBhIShrbYXVrvv++qPL76CsaPd6WtsjI3\n75e/PPoOOL/flYLuvbe6mrFbN/jRj9zU1O+/OezZ4y5Gaj4TcPCgKzF06OBKYZWv6emuwbVDB6v6\nOd5ZwjCtiqprHH3hBdfgd/nl0KHDNnbufIDdu5+gvLwAAJE4oqOT8fmSq16TkkbTseM0UlJOxfWa\n3zzKyuChh1x9+fjxrn2kvrYNVXfHXG6uO4/j/S4s0zpYwjBtRllZLtnZL1NWthe//xDl5YeqXsvK\nDpKfvwzVUmJiOtGx41Q6dpxGWtoZREXF1brPigo/RUXryc9fTn7+MgoKllNSspsTTvhvunW7rupO\nL2NaA0sYxnj8/kMcOPAm+/cv5ODBNykvL8DnSyYhYSgi0YhEeSUP9+r351BQsIqKisMA+HyJJCaO\nRLWCQ4f+j+Tk8Zx88uMkJAyM7IkZ00wsYRgTRHl5Mbm577F//z84fPgbVCuAclQrUC0HKoiKak9S\n0kgSE0eTlDSa9u1PQsSHqrJ37zNs3vwzyssL6dXrl5xwwpyj2k0qKvwUFKwkN/cDysqyUfWjWo6q\n3zuWn3btTqZ79/9nHT2aY4IlDGPCpLR0L5s338i+fQto334wJ5/8GCJx5OYuITf3ffLyPqK8PB+A\nqKh4RKIBn1ea8SESRWnpHuLietK371w6dZpR69Pwqkp+/lIOHnyHlJTTSE2d0KztMMaAJYxIh2Ha\ngP37X2fTpuspKcmqmte+/QBSU08nNfV0UlImEhcX/Law3NwP2bz5RgoKVpKcPI4TT/wTKSnjqpb7\n/Xns3fscu3bNp7BwVdX82NiuZGRcRKdOF5OcPLbFu10xrZMlDGNagN+fz+7dfyE2tgupqROJi+sa\n8raqFezZ8wxbt/6C0tI9dOo0g86dLyc7++/s2/d3KioOk5g4kq5dZ9Gx4/fIy/uIffsWcODAG6iW\nEBfXi06dfkhy8lji4/vQrl1foqODj9xVVpZDcfFWiou3UVFxmNjYbsTFdSM2tnut3dirVuD3H6Ki\nopCYmM5ERYVz6BwTSZYwjDlO+P0F/Oc/c8nK+iMVFcX4fIl06nQJ3brNIilpdJD1D7F//z/Zt28B\nOTnveG0jTnR0WlXyUPVz+LBLEoEPRNbk8yUTF9edmJh0/P58/P5c/P5cyssPAe63QSSW9u1Pon37\ngVVTQsJA2rU7CZ+vXa37NscHSxjGHGeKi7eTn7+ctLSziY5OCmkbvz+fw4c3U1y8xUsOW6vei/i8\n5NGH+PjexMe716io9pSW7qakZCelpTspKXGT33/Qe34l1ZtSiI5OJSqqHcXFWykqWk9h4XqKi7fi\nxjoDEOLje3tJZEDVa1xcV0TiiIqKIyoq1nsfi2oZpaV7KCnZTWlp4LSPiorDVFQUHzGplhEf34eE\nhKEkJAwlMXEocXEnWFVcM7OEYYwJi/LyYg4f/pqiovUUFW2gqGgDhYXrOXx4IxUVxY3YYxQxMene\neCrxAVM7IIrDhzdTUrK9am2fL4mEhCEkJ3+LDh0mk5Iyoc5SjqpSXLydkpL/VCVBny+F6Ohke57G\n05CEYRWTxpiQ+XzxJCYOIzFx2BHzVSsoLv4PRUXrKSvLpqKiFNUSKircpFoKRBEb25W4uK7ExlZO\nneq988vvP0Rh4VoKC9dQULCGwsLV7Nz5EFlZf0QkjtTUCaSlnU1a2mRiYtKqHrh0r8vx+w8E2avg\n8yUTE5NO+/YDSUwcRkKCO6927U6qarNRLaekZGdVf2clJf8hPr4PHTtObZO3RYd7TO8pwAO4cbmf\nUNW5NZaLt/xcoAi4UlVXeMu2Afm4Yd/8oWRAK2EY0zaUlxeRm/shOTnvkpPzDoWFa49YLhJNQsIQ\n73maTNq1O5Hy8oKqNprKqaxsH4WF6ygqWl/VHlTZZlNeXkBJSdYR7USVfL5EOna8kM6dLyMtbVKT\nbndWVS+xFlJe7iZ3zArvWSH1XiuIje1GfHyPRh8rmGOihCHuG3wYOBvIApaKyCJV/SpgtXOA/t40\nFnjEe600SVX3hytGY8zxyedrT3r6FNLTpwBQUrKLnJx3KS8vIilpNAkJw/D54kPeX0VFKUVFGygo\nWE1h4SoKC9cTHZ1CfHwvrw2oF3FxvYiP70l+/jL27Pkb2dkvsXfvM8TGdqVTp0tITh5LWdk+Skv3\nBLTV7MHvP1j1g+9+/JXKZFBRUUR5eSHV7UL1i43tTkrKqSQnuykpaVSdXd00p7CVMETkVOB2Vf2O\n9/kXAKr6PwHrPAa8r6oveJ83Aqer6m6vhJHZkIRhJQxjTEspLy/mwIHX2bv3bxw8+GZASSSK2NjO\nxMZ2ITa2C9HRHbwHNwUQXDc07tXna09UVAI+X/UUFZVAVFQMEAWI19bitjl8+BsOHfqUvLxPq9p2\nRGJJTh7LiBHvN6pd5pgoYQDdgR0Bn7M4svRQ2zrdgd24e/r+JSLlwGOqOj/YQURkFjAL4ISmjChj\njDEN4PPF06nTdDp1mk5Z2QFKSnYSG9uFmJj0MD+RPxuAkpLdHDr0GYcOfYrfn9MijfjHcqP3aaq6\nU0Q6Ae+KyAZV/bDmSl4imQ+uhNHSQRpjTExMOjExzTDObQPExXUlI2MaGRnTWuyY4UxJO4GeAZ97\nePNCWkdVK1/3AQuBMWGL1BhjTL3CmTCWAv1FpI+IxAIXA4tqrLMIuFyccUCe136RICJJACKSAEwG\n1mKMMSZiwlYlpap+EbkBWIy7rfZJVV0nItd5yx8F3sTdUrsZd1vtVd7mnYGF3hOd0cDzqvp2uGI1\nxhhTP3vS2xhj2rCG3CVlz8YbY4wJiSUMY4wxIbGEYYwxJiSWMIwxxoSkVTV6i0g2sL2e1ToCbbF/\nKjvvtsXOu21pynn3UtWMUFZsVQkjFCKyLNQ7AloTO++2xc67bWmp87YqKWOMMSGxhGGMMSYkbTFh\nBO31tg2w825b7LzblhY57zbXhmGMMaZx2mIJwxhjTCNYwjDGGBOSNpMwRGSKiGwUkc0iMifS8YSL\niDwpIvtEZG3AvA4i8q6IbPJe0yIZYziISE8RWSIiX4nIOhH5L29+qz53EYkXkS9EZJV33r/z5rfq\n864kIj4RWSkir3uf28p5bxORNSLypYgs8+aF/dzbRMIQN17iw8A5wCBghogMimxUYfNXYEqNeXOA\n91S1P/Ce97m18QM/V9VBwDjgJ97fuLWfewlwhqoOB0YAU7yxZVr7eVf6L2B9wOe2ct4Ak1R1RMDz\nF2E/9zaRMHCj9W1W1S2qWgosAKZGOKaw8IaxPVhj9lTgae/908D3WjSoFqCqu1V1hfc+H/cj0p1W\nfu7qFHgfY7xJaeXnDSAiPYDzgCcCZrf6865D2M+9rSSM7sCOgM9Z3ry2orOq7vbe78ENUNVqiUhv\nYCTwOW3g3L1qmS+BfcC7qtomzhu4H/hvoCJgXls4b3AXBf8SkeUiMsubF/ZzD9uIe+bYpKoqIq32\nXmoRSQReAW5U1UPeqI1A6z13VS0HRohIKm6kyiE1lre68xaR84F9qrpcRE4Ptk5rPO8Ap6nqThHp\nBLwrIhsCF4br3NtKCWMn0DPgcw9vXluxV0S6Aniv+yIcT1iISAwuWTynqq96s9vEuQOoai6wBNeG\n1drPezzwXRHZhqtiPkNEnqX1nzcAqrrTe90HLMRVu4f93NtKwlgK9BeRPiISC1wMLIpwTC1pEXCF\n9/4K4J8RjCUsxBUl/gKsV9X7Aha16nMXkQyvZIGItAPOBjbQys9bVX+hqj1UtTfu//O/VXUmrfy8\nAUQkQUSSKt8Dk4G1tMC5t5knvUXkXFydpw94UlXvinBIYSEiLwCn47o73gv8FvgH8CJwAq7794tU\ntWbD+HFNRE4DPgLWUF2nfRuuHaPVnruIDMM1cPpwF4AvquodIpJOKz7vQF6V1M2qen5bOG8R6Ysr\nVYBrVnheVe9qiXNvMwnDGGNM07SVKiljjDFNZAnDGGNMSCxhGGOMCYklDGOMMSGxhGGMMSYkljCM\nqYeIlHu9glZOzdapm4j0DuxZ2JhjmXUNYkz9DqvqiEgHYUykWQnDmEbyxiS4xxuX4AsR6efN7y0i\n/xaR1SLynoic4M3vLCILvbErVonIt7xd+UTkcW88i3e8J7YRkdne+B6rRWRBhE7TmCqWMIypX7sa\nVVI/DFiWp6pDgf/F9SQA8BDwtKoOA54DHvTmPwh84I1dMQpY583vDzysqoOBXOD73vw5wEhvP9eF\n6+SMCZU96W1MPUSkQFUTg8zfhhu8aIvX8eEeVU0Xkf1AV1Ut8+bvVtWOIpIN9FDVkoB99MZ1Sd7f\n+3wrEKOqd4rI20ABrmuXfwSMe2FMRFgJw5im0VreN0RJwPtyqtsWz8ONFDkKWCoi1uZoIsoShjFN\n88OA10+995/gelAFuBTXKSK4YTOvh6pBj1Jq26mIRAE9VXUJcCuQAhxVyjGmJdkVizH1a+eNaFfp\nbVWtvLU2TURW40oJM7x5PwWeEpFbgGzgKm/+fwHzReQaXEniemA3wfmAZ72kIsCD3ngXxkSMtWEY\n00heG0amqu6PdCzGtASrkjLGGBMSK2EYY4wJiZUwjDHGhMQShjHGmJBYwjDGGBMSSxjGGGNCYgnD\nGGNMSP4/ybL9LbUTtyUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc31c82ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "print(len(acc))\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9472/10000 [===========================>..] - ETA: 0s\n",
      "Test accuracy: 97.72999999999999 %\n",
      "Great job!\n"
     ]
    }
   ],
   "source": [
    "# Test score...\n",
    "test_predictions = model.predict_proba(X_test).argmax(axis=-1)\n",
    "test_answers = y_test.argmax(axis=-1)\n",
    "\n",
    "test_accuracy = np.mean(test_predictions==test_answers)\n",
    "\n",
    "print(\"\\nTest accuracy: {} %\".format(test_accuracy*100))\n",
    "\n",
    "assert test_accuracy>=0.92,\"Logistic regression can do better!\"\n",
    "assert test_accuracy>=0.975,\"Your network can do better!\"\n",
    "print(\"Great job!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer_submitter = grading.Grader(\"0ybD9ZxxEeea8A6GzH-6CA\")\n",
    "answer_submitter.set_answer(\"N56DR\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "answer_submitter.submit('jay.urbain@gmail.com', 'UC8V2hBDKDl4tPKn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips & tricks\n",
    "\n",
    "Here are some tips on what you could do. Don't worry, to reach the passing threshold you don't need to try all the ideas listed here, feel free to stop once you reach the 0.975 accuracy mark.\n",
    "\n",
    " * __Network size__\n",
    "   * More neurons, \n",
    "   * More layers, ([docs](https://keras.io/))\n",
    "\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    "\n",
    " * __Early Stopping__\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "     \n",
    "\n",
    " * __Faster optimization__\n",
    "   * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "\n",
    "\n",
    " * __Regularize__ to prevent overfitting\n",
    "   * Add some L2 weight norm to the loss function, theano will do the rest\n",
    "     * Can be done manually or via - https://keras.io/regularizers/\n",
    "   \n",
    "   \n",
    " * __Data augmemntation__ - getting 5x as large dataset for free is a great deal\n",
    "   * https://keras.io/preprocessing/image/\n",
    "   * Zoom-in+slice = move\n",
    "   * Rotate+zoom(to remove black stripes)\n",
    "   * any other perturbations\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                19625     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 20,535\n",
      "Trainable params: 20,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
